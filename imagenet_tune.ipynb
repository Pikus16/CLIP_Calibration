{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/content_understanding/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import open_clip\n",
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "from PIL import Image\n",
    "import open_clip\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from sklearn import calibration\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.tree import DecisionTreeRegressor as DT\n",
    "from sklearn.isotonic import IsotonicRegression as IR\n",
    "from scipy.stats import norm\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:5' if torch.cuda.is_available() else 'cpu')\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'ViT-B-16'\n",
    "pretrained_dset = 'laion400m_e31'\n",
    "\n",
    "model, _, preprocess = open_clip.create_model_and_transforms(model_name,\n",
    "    pretrained=pretrained_dset,\n",
    "    device=device)\n",
    "tokenizer = open_clip.get_tokenizer(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_test = datasets.ImageFolder(f'/home/ubuntu/data/Imagenet/ILSVRC/Data/CLS-LOC/train/', transform=preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:18<00:00, 12.74it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_template = 'a photo of a {}.'\n",
    "np.random.seed(0)\n",
    "\n",
    "subset_in_classes = []\n",
    "for c in tqdm(range(len(imagenet_test.classes))):\n",
    "    appending = np.random.choice(np.where(np.array(imagenet_test.targets) == c)[0], 50, replace=False)\n",
    "    subset_in_classes.extend(appending.tolist())\n",
    "subset = torch.utils.data.Subset(imagenet_test, subset_in_classes)\n",
    "subset.classes = imagenet_test.classes\n",
    "imagenet_test = subset\n",
    "len(imagenet_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_to_consider = [\n",
    "    ('ViT-B-16' , 'laion2b_s34b_b88k'),\n",
    "    ('ViT-L-14' , 'laion2b_s32b_b82k'),\n",
    "    ('ViT-B-32' , 'laion2b_s34b_b79k'),\n",
    "\n",
    "    ('ViT-B-16' , 'openai'),\n",
    "    ('ViT-L-14' , 'openai'),\n",
    "    ('ViT-B-32' , 'openai'),\n",
    "\n",
    "    ('ViT-B-16' , 'laion400m_e31'),\n",
    "    ('ViT-L-14' , 'laion400m_e31'),\n",
    "    ('ViT-B-32' , 'laion400m_e31'),\n",
    "\n",
    "    ('RN50', 'openai'),\n",
    "    ('RN50', 'yfcc15m'),\n",
    "    ('RN50', 'cc12m'),\n",
    "\n",
    "    ('ViT-H-14', 'laion2b_s32b_b79k')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [29:06<00:00, 134.32s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ViT-B-16;laion2b_s34b_b88k': 1.3878337144851685,\n",
       " 'ViT-L-14;laion2b_s32b_b82k': 1.4129570722579956,\n",
       " 'ViT-B-32;laion2b_s34b_b79k': 1.4092495441436768,\n",
       " 'ViT-B-16;openai': 0.9825258851051331,\n",
       " 'ViT-L-14;openai': 1.0273551940917969,\n",
       " 'ViT-B-32;openai': 0.9789162874221802,\n",
       " 'ViT-B-16;laion400m_e31': 1.6131701469421387,\n",
       " 'ViT-L-14;laion400m_e31': 1.7537566423416138,\n",
       " 'ViT-B-32;laion400m_e31': 1.37242591381073,\n",
       " 'RN50;openai': 0.9742085933685303,\n",
       " 'RN50;yfcc15m': 2.5651497840881348,\n",
       " 'RN50;cc12m': 2.662893295288086,\n",
       " 'ViT-H-14;laion2b_s32b_b79k': 1.5119352340698242}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#imagenet_mapping = map_imagenet_to_readable_label()\n",
    "#imagenet_test.classes = [imagenet_mapping[x] for x in imagenet_test.classes ]\n",
    "\n",
    "all_temps = {}\n",
    "for model_name, pretrained_dset in tqdm(models_to_consider):\n",
    "    model, _, preprocess = open_clip.create_model_and_transforms(model_name,\n",
    "        pretrained=pretrained_dset,\n",
    "        device=device)\n",
    "    tokenizer = open_clip.get_tokenizer(model_name)\n",
    "    imagenet_test.dataset.transform = preprocess\n",
    "    \n",
    "    image_features, actual = get_image_features(model, imagenet_test, batch_size=128,\n",
    "        device = device)\n",
    "\n",
    "    actual = torch.IntTensor(actual).to(device).long()\n",
    "\n",
    "    text = tokenizer([text_template.replace('{}',x) for x in imagenet_test.classes])\n",
    "    with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "        text_features = model.encode_text(text.to(device))\n",
    "        text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "        \n",
    "    text_probs = (100.0 * image_features @ text_features.T)\n",
    "\n",
    "    ## Setup LBGFS\n",
    "    temperature = nn.Parameter((torch.ones(1)).to(device))\n",
    "    args = {'temperature': temperature}\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Removing strong_wolfe line search results in jump after 50 epochs\n",
    "    optimizer = optim.LBFGS([temperature], lr=0.001, max_iter=1000, line_search_fn='strong_wolfe')\n",
    "\n",
    "    temps = []\n",
    "    losses = []\n",
    "    def _eval():\n",
    "        loss = criterion(T_scaling(text_probs, args), actual)\n",
    "        loss.backward()\n",
    "        temps.append(temperature.item())\n",
    "        losses.append(loss)\n",
    "        return loss\n",
    "    optimizer.step(_eval)\n",
    "    all_temps[model_name+';' + pretrained_dset] = temperature.item()\n",
    "all_temps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "cifar100, _ = get_test_set('CIFAR100', preprocess)\n",
    "cifar10, _ = get_test_set('CIFAR10', preprocess)\n",
    "#sun_dset = datasets.LSUN(root=f'/home/ubuntu/data/LSUN', classes='test', transform=preprocess)\n",
    "food_dset = datasets.Food101('/home/ubuntu/data/Food101/', split='test', transform=preprocess,download=True)\n",
    "#sun_dset = datasets.SUN397()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [06:40<00:00, 30.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [06:38<00:00, 30.66s/it]\n",
      "100%|██████████| 13/13 [14:19<00:00, 66.15s/it]\n"
     ]
    }
   ],
   "source": [
    "dataset_eces = {}\n",
    "dataset_accs = {}\n",
    "for dataset_name in ['CIFAR100', 'CIFAR10', 'Food101', 'SUN397']:\n",
    "    dset,_ = get_test_set(dataset_name, None)\n",
    "    model_eces = {}\n",
    "    model_accs = {}\n",
    "    for model_legend, temp in tqdm(all_temps.items()):\n",
    "        model_name, pretrained_dset = model_legend.split(';')\n",
    "        model, _, preprocess = open_clip.create_model_and_transforms(model_name,\n",
    "            pretrained=pretrained_dset,\n",
    "            device=device)\n",
    "        tokenizer = open_clip.get_tokenizer(model_name)\n",
    "        dset.transform = preprocess\n",
    "        _ , templates = get_openai_prompts(dataset_name)\n",
    "\n",
    "        template_eces = []\n",
    "        template_accs = []\n",
    "        image_features, actual = get_image_features(\n",
    "            model,  dset,  batch_size=batch_size, device=device\n",
    "        )\n",
    "        for text_template in templates:\n",
    "            #predictions, actual, probs = get_preds(model, tokenizer, dset, \n",
    "            #    text_template=text_template, temp_scaling=temp, device=device)\n",
    "\n",
    "            predictions, probs = get_preds_from_img_features(model, tokenizer, dset, image_features, text_template=text_template, temp_scaling=temp,\n",
    "                device = device)\n",
    "\n",
    "            ECE, _, acc = get_metrics(predictions, actual, probs)\n",
    "            template_eces.append(ECE)\n",
    "            template_accs.append(acc)\n",
    "        \n",
    "        model_eces[model_legend] = template_eces\n",
    "        model_accs[model_legend] = template_accs\n",
    "    dataset_eces[dataset_name] = model_eces\n",
    "    dataset_accs[dataset_name] = model_eces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ViT-B-16;laion2b_s34b_b88k</th>\n",
       "      <th>ViT-L-14;laion2b_s32b_b82k</th>\n",
       "      <th>ViT-B-32;laion2b_s34b_b79k</th>\n",
       "      <th>ViT-B-16;openai</th>\n",
       "      <th>ViT-L-14;openai</th>\n",
       "      <th>ViT-B-32;openai</th>\n",
       "      <th>ViT-B-16;laion400m_e31</th>\n",
       "      <th>ViT-L-14;laion400m_e31</th>\n",
       "      <th>ViT-B-32;laion400m_e31</th>\n",
       "      <th>RN50;openai</th>\n",
       "      <th>RN50;yfcc15m</th>\n",
       "      <th>RN50;cc12m</th>\n",
       "      <th>ViT-H-14;laion2b_s32b_b79k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.028102</td>\n",
       "      <td>0.014133</td>\n",
       "      <td>0.015249</td>\n",
       "      <td>0.031657</td>\n",
       "      <td>0.041401</td>\n",
       "      <td>0.025413</td>\n",
       "      <td>0.024479</td>\n",
       "      <td>0.010244</td>\n",
       "      <td>0.027594</td>\n",
       "      <td>0.034527</td>\n",
       "      <td>0.135337</td>\n",
       "      <td>0.100776</td>\n",
       "      <td>0.013398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.046665</td>\n",
       "      <td>0.029012</td>\n",
       "      <td>0.049906</td>\n",
       "      <td>0.057445</td>\n",
       "      <td>0.039721</td>\n",
       "      <td>0.051354</td>\n",
       "      <td>0.040410</td>\n",
       "      <td>0.015074</td>\n",
       "      <td>0.063761</td>\n",
       "      <td>0.067796</td>\n",
       "      <td>0.135968</td>\n",
       "      <td>0.089820</td>\n",
       "      <td>0.027745</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ViT-B-16;laion2b_s34b_b88k  ViT-L-14;laion2b_s32b_b82k  \\\n",
       "0                    0.028102                    0.014133   \n",
       "1                    0.046665                    0.029012   \n",
       "\n",
       "   ViT-B-32;laion2b_s34b_b79k  ViT-B-16;openai  ViT-L-14;openai  \\\n",
       "0                    0.015249         0.031657         0.041401   \n",
       "1                    0.049906         0.057445         0.039721   \n",
       "\n",
       "   ViT-B-32;openai  ViT-B-16;laion400m_e31  ViT-L-14;laion400m_e31  \\\n",
       "0         0.025413                0.024479                0.010244   \n",
       "1         0.051354                0.040410                0.015074   \n",
       "\n",
       "   ViT-B-32;laion400m_e31  RN50;openai  RN50;yfcc15m  RN50;cc12m  \\\n",
       "0                0.027594     0.034527      0.135337    0.100776   \n",
       "1                0.063761     0.067796      0.135968    0.089820   \n",
       "\n",
       "   ViT-H-14;laion2b_s32b_b79k  \n",
       "0                    0.013398  \n",
       "1                    0.027745  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_eces_supervised = {}\n",
    "dataset_accs_supervised = {}\n",
    "for dataset_name in ['CIFAR100', 'CIFAR10', 'Food101', 'SUN397']:\n",
    "    dset,_ = get_test_set(dataset_name, None)\n",
    "    model_eces = {}\n",
    "    model_accs = {}\n",
    "    for model_legend, temp in tqdm(all_temps.items()):\n",
    "        model_name, pretrained_dset = model_legend.split(';')\n",
    "        model, _, preprocess = open_clip.create_model_and_transforms(model_name,\n",
    "            pretrained=pretrained_dset,\n",
    "            device=device)\n",
    "        tokenizer = open_clip.get_tokenizer(model_name)\n",
    "        if isinstance(dset, torch.utils.data.dataset.Subset):\n",
    "            dset.dataset.transform = preprocess\n",
    "        else:\n",
    "            dset.transform = preprocess\n",
    "        _ , templates = get_openai_prompts(dataset_name)\n",
    "\n",
    "        template_eces = []\n",
    "        template_accs = []\n",
    "        image_features, actual = get_image_features(\n",
    "            model,  dset,  batch_size=batch_size, device=device\n",
    "        )\n",
    "        for text_template in templates:\n",
    "            #predictions, actual, probs = get_preds(model, tokenizer, dset, \n",
    "            #    text_template=text_template, temp_scaling=temp, device=device)\n",
    "\n",
    "            predictions, probs = get_preds_from_img_features(model, tokenizer, dset, image_features, text_template=text_template, temp_scaling=temp,\n",
    "                device = device)\n",
    "\n",
    "            ECE, _, acc = get_metrics(predictions, actual, probs)\n",
    "            template_eces.append(ECE)\n",
    "            template_accs.append(acc)\n",
    "        \n",
    "        model_eces[model_legend] = template_eces\n",
    "        model_accs[model_legend] = template_accs\n",
    "    dataset_eces_supervised[dataset_name] = model_eces\n",
    "    dataset_accs_supervised[dataset_name] = model_eces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "a photo of a {}.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((0.06008501325334824, 0.19970703125, 0.9174),\n",
       " (0.034525964367322824, 0.19967076182365417, 0.9175))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_legend =  'ViT-B-16;laion400m_e31'\n",
    "model_name, pretrained_dset = model_legend.split(';')\n",
    "model, _, preprocess = open_clip.create_model_and_transforms(model_name,\n",
    "            pretrained=pretrained_dset,\n",
    "            device=device)\n",
    "tokenizer = open_clip.get_tokenizer(model_name)\n",
    "dset,_ = get_test_set('CIFAR10', preprocess)\n",
    "_ , templates = get_openai_prompts('CIFAR10')\n",
    "print(templates[0])\n",
    "image_features, actual = get_image_features(\n",
    "        model,  dset,  batch_size=batch_size, device=device\n",
    "    )\n",
    "predictions, probs = get_preds_from_img_features(model, tokenizer, dset, image_features, text_template=templates[0], \n",
    "        #temp_scaling=temp,\n",
    "        device = device)\n",
    "predictions_, actual_, probs_ = get_preds(model, tokenizer, dset, text_template=templates[0], device=device)\n",
    "get_metrics(predictions, actual, probs), get_metrics(predictions_, actual_, probs_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [06:52<00:00, 31.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ViT-B-16;laion2b_s34b_b88k  ViT-L-14;laion2b_s32b_b82k  \\\n",
      "0                     0.058503                    0.045934   \n",
      "1                     0.045820                    0.038335   \n",
      "2                     0.060482                    0.039551   \n",
      "3                     0.059873                    0.049759   \n",
      "4                     0.066750                    0.043859   \n",
      "5                     0.062486                    0.050213   \n",
      "6                     0.062093                    0.053934   \n",
      "7                     0.053304                    0.045275   \n",
      "8                     0.069938                    0.057849   \n",
      "9                     0.048214                    0.046141   \n",
      "10                    0.040250                    0.036563   \n",
      "11                    0.053200                    0.037751   \n",
      "12                    0.061325                    0.051173   \n",
      "13                    0.063761                    0.046218   \n",
      "14                    0.054451                    0.048778   \n",
      "15                    0.053151                    0.046896   \n",
      "16                    0.045382                    0.040281   \n",
      "17                    0.068705                    0.056568   \n",
      "\n",
      "    ViT-B-32;laion2b_s34b_b79k  ViT-B-16;openai  ViT-L-14;openai  \\\n",
      "0                     0.072348         0.121402         0.117865   \n",
      "1                     0.050802         0.095473         0.102713   \n",
      "2                     0.064510         0.071126         0.113897   \n",
      "3                     0.066378         0.108485         0.078968   \n",
      "4                     0.071112         0.099207         0.075937   \n",
      "5                     0.064337         0.114293         0.105366   \n",
      "6                     0.068780         0.108451         0.100493   \n",
      "7                     0.072023         0.130645         0.143433   \n",
      "8                     0.090431         0.106683         0.116753   \n",
      "9                     0.068185         0.148774         0.141616   \n",
      "10                    0.042161         0.120829         0.123818   \n",
      "11                    0.063971         0.100871         0.111189   \n",
      "12                    0.061481         0.139785         0.103225   \n",
      "13                    0.070204         0.127696         0.105246   \n",
      "14                    0.053712         0.136247         0.146812   \n",
      "15                    0.055417         0.135310         0.128102   \n",
      "16                    0.059387         0.166664         0.167992   \n",
      "17                    0.072097         0.140142         0.137583   \n",
      "\n",
      "    ViT-B-32;openai  ViT-B-16;laion400m_e31  ViT-L-14;laion400m_e31  \\\n",
      "0          0.110404                0.102299                0.110380   \n",
      "1          0.091311                0.104224                0.093059   \n",
      "2          0.069233                0.110759                0.093130   \n",
      "3          0.090336                0.108625                0.101925   \n",
      "4          0.050484                0.116391                0.102179   \n",
      "5          0.126630                0.109870                0.107615   \n",
      "6          0.116463                0.114862                0.110457   \n",
      "7          0.129102                0.105153                0.111899   \n",
      "8          0.120098                0.125752                0.132232   \n",
      "9          0.151651                0.104212                0.118815   \n",
      "10         0.135985                0.102549                0.095930   \n",
      "11         0.105480                0.107702                0.101679   \n",
      "12         0.121141                0.106990                0.115826   \n",
      "13         0.087463                0.116002                0.110639   \n",
      "14         0.171092                0.111427                0.118801   \n",
      "15         0.149140                0.108083                0.114800   \n",
      "16         0.160490                0.100842                0.112267   \n",
      "17         0.128236                0.140139                0.157272   \n",
      "\n",
      "    ViT-B-32;laion400m_e31  RN50;openai  RN50;yfcc15m  RN50;cc12m  \\\n",
      "0                 0.076371     0.117191      0.392679    0.389912   \n",
      "1                 0.077769     0.087233      0.337625    0.383807   \n",
      "2                 0.078300     0.042404      0.409148    0.363756   \n",
      "3                 0.078433     0.078704      0.597304    0.333214   \n",
      "4                 0.085470     0.058768      0.530208    0.385945   \n",
      "5                 0.065901     0.101383      0.342650    0.375240   \n",
      "6                 0.072624     0.104138      0.378823    0.383190   \n",
      "7                 0.067994     0.112516      0.448670    0.325035   \n",
      "8                 0.082396     0.113385      0.427107    0.400563   \n",
      "9                 0.067266     0.123492      0.429011    0.418346   \n",
      "10                0.067955     0.107606      0.339653    0.366755   \n",
      "11                0.071075     0.065681      0.426691    0.320966   \n",
      "12                0.064783     0.090253      0.487545    0.345652   \n",
      "13                0.074718     0.088024      0.429599    0.394679   \n",
      "14                0.053929     0.111538      0.367622    0.384283   \n",
      "15                0.061849     0.101622      0.392982    0.389252   \n",
      "16                0.049667     0.128980      0.413619    0.338823   \n",
      "17                0.062791     0.113888      0.453722    0.450011   \n",
      "\n",
      "    ViT-H-14;laion2b_s32b_b79k  \n",
      "0                     0.053100  \n",
      "1                     0.045346  \n",
      "2                     0.047010  \n",
      "3                     0.052364  \n",
      "4                     0.054513  \n",
      "5                     0.055070  \n",
      "6                     0.057776  \n",
      "7                     0.043528  \n",
      "8                     0.068385  \n",
      "9                     0.050647  \n",
      "10                    0.050975  \n",
      "11                    0.044438  \n",
      "12                    0.052352  \n",
      "13                    0.053711  \n",
      "14                    0.054190  \n",
      "15                    0.056108  \n",
      "16                    0.054723  \n",
      "17                    0.072643  \n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [06:47<00:00, 31.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ViT-B-16;laion2b_s34b_b88k  ViT-L-14;laion2b_s32b_b82k  \\\n",
      "0                     0.010584                    0.007821   \n",
      "1                     0.003846                    0.004197   \n",
      "2                     0.007205                    0.003622   \n",
      "3                     0.011140                    0.007182   \n",
      "4                     0.009263                    0.006535   \n",
      "5                     0.012927                    0.006660   \n",
      "6                     0.009915                    0.006664   \n",
      "7                     0.015371                    0.009377   \n",
      "8                     0.013392                    0.028946   \n",
      "9                     0.008501                    0.007654   \n",
      "10                    0.002923                    0.004935   \n",
      "11                    0.006695                    0.005682   \n",
      "12                    0.011906                    0.004308   \n",
      "13                    0.009057                    0.004868   \n",
      "14                    0.010353                    0.006806   \n",
      "15                    0.008436                    0.007017   \n",
      "16                    0.014519                    0.008805   \n",
      "17                    0.027452                    0.008615   \n",
      "\n",
      "    ViT-B-32;laion2b_s34b_b79k  ViT-B-16;openai  ViT-L-14;openai  \\\n",
      "0                     0.015267         0.052941         0.048764   \n",
      "1                     0.011603         0.053788         0.053379   \n",
      "2                     0.014839         0.029693         0.039435   \n",
      "3                     0.012595         0.049254         0.037289   \n",
      "4                     0.013023         0.040622         0.033968   \n",
      "5                     0.015577         0.058721         0.055635   \n",
      "6                     0.015433         0.069264         0.052584   \n",
      "7                     0.023952         0.045648         0.058676   \n",
      "8                     0.025949         0.087799         0.101489   \n",
      "9                     0.015310         0.063762         0.076234   \n",
      "10                    0.007500         0.064879         0.057954   \n",
      "11                    0.012888         0.049141         0.065425   \n",
      "12                    0.012587         0.068466         0.059436   \n",
      "13                    0.013329         0.060841         0.054055   \n",
      "14                    0.011432         0.058770         0.078196   \n",
      "15                    0.012720         0.075765         0.075881   \n",
      "16                    0.023213         0.064193         0.079541   \n",
      "17                    0.020180         0.126186         0.120056   \n",
      "\n",
      "    ViT-B-32;openai  ViT-B-16;laion400m_e31  ViT-L-14;laion400m_e31  \\\n",
      "0          0.049213                0.034623                0.028494   \n",
      "1          0.040932                0.032706                0.021722   \n",
      "2          0.021482                0.029398                0.024675   \n",
      "3          0.041575                0.034543                0.026291   \n",
      "4          0.012795                0.029764                0.027248   \n",
      "5          0.071265                0.039498                0.027768   \n",
      "6          0.057652                0.036106                0.031694   \n",
      "7          0.044401                0.046037                0.036159   \n",
      "8          0.088463                0.036386                0.035079   \n",
      "9          0.078749                0.035678                0.034645   \n",
      "10         0.078691                0.033514                0.022363   \n",
      "11         0.050637                0.035034                0.027535   \n",
      "12         0.065203                0.032993                0.029294   \n",
      "13         0.038884                0.031916                0.030858   \n",
      "14         0.101858                0.039493                0.030308   \n",
      "15         0.073507                0.035712                0.034184   \n",
      "16         0.063764                0.044679                0.037688   \n",
      "17         0.122147                0.040594                0.048531   \n",
      "\n",
      "    ViT-B-32;laion400m_e31  RN50;openai  RN50;yfcc15m  RN50;cc12m  \\\n",
      "0                 0.031858     0.076289      0.298224    0.243863   \n",
      "1                 0.034588     0.089701      0.177471    0.240306   \n",
      "2                 0.023541     0.029134      0.274205    0.251653   \n",
      "3                 0.034430     0.052215      0.182620    0.175592   \n",
      "4                 0.029081     0.041185      0.229319    0.139610   \n",
      "5                 0.029669     0.081426      0.196032    0.221879   \n",
      "6                 0.029563     0.048513      0.223634    0.227368   \n",
      "7                 0.035480     0.041658      0.246183    0.250358   \n",
      "8                 0.040406     0.097298      0.279534    0.301198   \n",
      "9                 0.034844     0.076154      0.338492    0.293334   \n",
      "10                0.033034     0.092313      0.199082    0.261134   \n",
      "11                0.027735     0.053063      0.266768    0.260330   \n",
      "12                0.038848     0.072184      0.307081    0.178683   \n",
      "13                0.037137     0.057845      0.298278    0.189444   \n",
      "14                0.032729     0.076811      0.266216    0.274836   \n",
      "15                0.031548     0.054111      0.312276    0.217911   \n",
      "16                0.033064     0.073716      0.239136    0.372883   \n",
      "17                0.028963     0.049731      0.321638    0.364339   \n",
      "\n",
      "    ViT-H-14;laion2b_s32b_b79k  \n",
      "0                     0.009523  \n",
      "1                     0.004875  \n",
      "2                     0.003986  \n",
      "3                     0.007756  \n",
      "4                     0.006740  \n",
      "5                     0.007089  \n",
      "6                     0.008725  \n",
      "7                     0.010667  \n",
      "8                     0.006436  \n",
      "9                     0.011080  \n",
      "10                    0.003662  \n",
      "11                    0.002707  \n",
      "12                    0.006242  \n",
      "13                    0.006712  \n",
      "14                    0.004902  \n",
      "15                    0.006032  \n",
      "16                    0.009753  \n",
      "17                    0.017397  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [14:27<00:00, 66.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ViT-B-16;laion2b_s34b_b88k  ViT-L-14;laion2b_s32b_b82k  \\\n",
      "0                    0.017865                    0.015185   \n",
      "\n",
      "   ViT-B-32;laion2b_s34b_b79k  ViT-B-16;openai  ViT-L-14;openai  \\\n",
      "0                    0.028567         0.029396         0.015401   \n",
      "\n",
      "   ViT-B-32;openai  ViT-B-16;laion400m_e31  ViT-L-14;laion400m_e31  \\\n",
      "0         0.029977                0.044579                0.033489   \n",
      "\n",
      "   ViT-B-32;laion400m_e31  RN50;openai  RN50;yfcc15m  RN50;cc12m  \\\n",
      "0                0.025616     0.047133      0.228004    0.268225   \n",
      "\n",
      "   ViT-H-14;laion2b_s32b_b79k  \n",
      "0                    0.015839  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/13 [01:59<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/ubuntu/code/clip_miscalibration/imagenet_tune.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbenp_8gpu/home/ubuntu/code/clip_miscalibration/imagenet_tune.ipynb#Y101sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m _ , templates \u001b[39m=\u001b[39m get_openai_prompts(dataset_name)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbenp_8gpu/home/ubuntu/code/clip_miscalibration/imagenet_tune.ipynb#Y101sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m template_eces \u001b[39m=\u001b[39m []\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bbenp_8gpu/home/ubuntu/code/clip_miscalibration/imagenet_tune.ipynb#Y101sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m image_features, actual \u001b[39m=\u001b[39m get_image_features(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbenp_8gpu/home/ubuntu/code/clip_miscalibration/imagenet_tune.ipynb#Y101sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m     model,  dset,  batch_size\u001b[39m=\u001b[39;49mbatch_size, device\u001b[39m=\u001b[39;49mdevice\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbenp_8gpu/home/ubuntu/code/clip_miscalibration/imagenet_tune.ipynb#Y101sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbenp_8gpu/home/ubuntu/code/clip_miscalibration/imagenet_tune.ipynb#Y101sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mfor\u001b[39;00m text_template \u001b[39min\u001b[39;00m templates:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbenp_8gpu/home/ubuntu/code/clip_miscalibration/imagenet_tune.ipynb#Y101sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m     \u001b[39m#predictions, actual, probs = get_preds(model, tokenizer, dset, \u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbenp_8gpu/home/ubuntu/code/clip_miscalibration/imagenet_tune.ipynb#Y101sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m     \u001b[39m#    text_template=text_template, temp_scaling=temp, device=device)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbenp_8gpu/home/ubuntu/code/clip_miscalibration/imagenet_tune.ipynb#Y101sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m     predictions, probs \u001b[39m=\u001b[39m get_preds_from_img_features(model, tokenizer, dset, image_features, text_template\u001b[39m=\u001b[39mtext_template, \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbenp_8gpu/home/ubuntu/code/clip_miscalibration/imagenet_tune.ipynb#Y101sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m         \u001b[39m#temp_scaling=temp,\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbenp_8gpu/home/ubuntu/code/clip_miscalibration/imagenet_tune.ipynb#Y101sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m         device \u001b[39m=\u001b[39m device)\n",
      "File \u001b[0;32m~/code/clip_miscalibration/util.py:18\u001b[0m, in \u001b[0;36mget_image_features\u001b[0;34m(model, dset, batch_size, device)\u001b[0m\n\u001b[1;32m     16\u001b[0m actual \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([])\n\u001b[1;32m     17\u001b[0m all_img_features \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[39mfor\u001b[39;00m i, (images, labels) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(dataloader, \u001b[39m0\u001b[39m):\n\u001b[1;32m     19\u001b[0m     images \u001b[39m=\u001b[39m images\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     20\u001b[0m     model\u001b[39m.\u001b[39meval()\n",
      "File \u001b[0;32m~/anaconda3/envs/content_understanding/lib/python3.8/site-packages/torch/utils/data/dataloader.py:652\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    650\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    651\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 652\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    653\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    654\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    655\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    656\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/content_understanding/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1330\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1327\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_data(data)\n\u001b[1;32m   1329\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m-> 1330\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data()\n\u001b[1;32m   1331\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1332\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable:\n\u001b[1;32m   1333\u001b[0m     \u001b[39m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/content_understanding/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1296\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1292\u001b[0m     \u001b[39m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1293\u001b[0m     \u001b[39m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1294\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1295\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m-> 1296\u001b[0m         success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_get_data()\n\u001b[1;32m   1297\u001b[0m         \u001b[39mif\u001b[39;00m success:\n\u001b[1;32m   1298\u001b[0m             \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/anaconda3/envs/content_understanding/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1134\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1121\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_get_data\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m_utils\u001b[39m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1122\u001b[0m     \u001b[39m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1123\u001b[0m     \u001b[39m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1131\u001b[0m     \u001b[39m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m     \u001b[39m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1134\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m   1135\u001b[0m         \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n\u001b[1;32m   1136\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1137\u001b[0m         \u001b[39m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m         \u001b[39m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1139\u001b[0m         \u001b[39m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/content_understanding/lib/python3.8/multiprocessing/queues.py:107\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[39mif\u001b[39;00m block:\n\u001b[1;32m    106\u001b[0m     timeout \u001b[39m=\u001b[39m deadline \u001b[39m-\u001b[39m time\u001b[39m.\u001b[39mmonotonic()\n\u001b[0;32m--> 107\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout):\n\u001b[1;32m    108\u001b[0m         \u001b[39mraise\u001b[39;00m Empty\n\u001b[1;32m    109\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_poll():\n",
      "File \u001b[0;32m~/anaconda3/envs/content_understanding/lib/python3.8/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_closed()\n\u001b[1;32m    256\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout)\n",
      "File \u001b[0;32m~/anaconda3/envs/content_understanding/lib/python3.8/multiprocessing/connection.py:424\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_poll\u001b[39m(\u001b[39mself\u001b[39m, timeout):\n\u001b[0;32m--> 424\u001b[0m     r \u001b[39m=\u001b[39m wait([\u001b[39mself\u001b[39;49m], timeout)\n\u001b[1;32m    425\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mbool\u001b[39m(r)\n",
      "File \u001b[0;32m~/anaconda3/envs/content_understanding/lib/python3.8/multiprocessing/connection.py:931\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    928\u001b[0m     deadline \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mmonotonic() \u001b[39m+\u001b[39m timeout\n\u001b[1;32m    930\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     ready \u001b[39m=\u001b[39m selector\u001b[39m.\u001b[39;49mselect(timeout)\n\u001b[1;32m    932\u001b[0m     \u001b[39mif\u001b[39;00m ready:\n\u001b[1;32m    933\u001b[0m         \u001b[39mreturn\u001b[39;00m [key\u001b[39m.\u001b[39mfileobj \u001b[39mfor\u001b[39;00m (key, events) \u001b[39min\u001b[39;00m ready]\n",
      "File \u001b[0;32m~/anaconda3/envs/content_understanding/lib/python3.8/selectors.py:415\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m ready \u001b[39m=\u001b[39m []\n\u001b[1;32m    414\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 415\u001b[0m     fd_event_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_selector\u001b[39m.\u001b[39;49mpoll(timeout)\n\u001b[1;32m    416\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mInterruptedError\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     \u001b[39mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#dataset_eces_uncalib = {}\n",
    "for dataset_name in ['CIFAR100', 'CIFAR10', 'Food101', 'SUN397']:\n",
    "    dset,_ = get_test_set(dataset_name, None)\n",
    "    model_eces = {}\n",
    "    for model_legend, _ in tqdm(all_temps.items()):\n",
    "        model_name, pretrained_dset = model_legend.split(';')\n",
    "        model, _, preprocess = open_clip.create_model_and_transforms(model_name,\n",
    "            pretrained=pretrained_dset,\n",
    "            device=device)\n",
    "        tokenizer = open_clip.get_tokenizer(model_name)\n",
    "        if isinstance(dset, torch.utils.data.dataset.Subset):\n",
    "            dset.dataset.transform = preprocess\n",
    "        else:\n",
    "            dset.transform = preprocess\n",
    "        _ , templates = get_openai_prompts(dataset_name)\n",
    "\n",
    "        template_eces = []\n",
    "        image_features, actual = get_image_features(\n",
    "            model,  dset,  batch_size=batch_size, device=device\n",
    "        )\n",
    "        for text_template in templates:\n",
    "            #predictions, actual, probs = get_preds(model, tokenizer, dset, \n",
    "            #    text_template=text_template, temp_scaling=temp, device=device)\n",
    "\n",
    "            predictions, probs = get_preds_from_img_features(model, tokenizer, dset, image_features, text_template=text_template, \n",
    "                #temp_scaling=temp,\n",
    "                device = device)\n",
    "\n",
    "            ECE, _, acc = get_metrics(predictions, actual, probs)\n",
    "            template_eces.append(ECE)\n",
    "        \n",
    "        model_eces[model_legend] = template_eces\n",
    "    dataset_eces_uncalib[dataset_name] = model_eces\n",
    "    print(pd.DataFrame(model_eces))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ViT-B-16;laion2b_s34b_b88k</th>\n",
       "      <th>ViT-L-14;laion2b_s32b_b82k</th>\n",
       "      <th>ViT-B-32;laion2b_s34b_b79k</th>\n",
       "      <th>ViT-B-16;openai</th>\n",
       "      <th>ViT-L-14;openai</th>\n",
       "      <th>ViT-B-32;openai</th>\n",
       "      <th>ViT-B-16;laion400m_e31</th>\n",
       "      <th>ViT-L-14;laion400m_e31</th>\n",
       "      <th>ViT-B-32;laion400m_e31</th>\n",
       "      <th>RN50;openai</th>\n",
       "      <th>RN50;yfcc15m</th>\n",
       "      <th>RN50;cc12m</th>\n",
       "      <th>ViT-H-14;laion2b_s32b_b79k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.017865</td>\n",
       "      <td>0.015185</td>\n",
       "      <td>0.028567</td>\n",
       "      <td>0.029396</td>\n",
       "      <td>0.015401</td>\n",
       "      <td>0.029977</td>\n",
       "      <td>0.044579</td>\n",
       "      <td>0.033489</td>\n",
       "      <td>0.025616</td>\n",
       "      <td>0.047133</td>\n",
       "      <td>0.228004</td>\n",
       "      <td>0.268225</td>\n",
       "      <td>0.015839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ViT-B-16;laion2b_s34b_b88k  ViT-L-14;laion2b_s32b_b82k  \\\n",
       "0                    0.017865                    0.015185   \n",
       "\n",
       "   ViT-B-32;laion2b_s34b_b79k  ViT-B-16;openai  ViT-L-14;openai  \\\n",
       "0                    0.028567         0.029396         0.015401   \n",
       "\n",
       "   ViT-B-32;openai  ViT-B-16;laion400m_e31  ViT-L-14;laion400m_e31  \\\n",
       "0         0.029977                0.044579                0.033489   \n",
       "\n",
       "   ViT-B-32;laion400m_e31  RN50;openai  RN50;yfcc15m  RN50;cc12m  \\\n",
       "0                0.025616     0.047133      0.228004    0.268225   \n",
       "\n",
       "   ViT-H-14;laion2b_s32b_b79k  \n",
       "0                    0.015839  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(dataset_eces_uncalib['Food101'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [1:01:07<00:00, 282.13s/it]\n"
     ]
    }
   ],
   "source": [
    "for dataset_name in ['SUN397']:\n",
    "    dset,_ = get_test_set(dataset_name, None)\n",
    "    model_eces = {}\n",
    "    for model_legend, temp in tqdm(all_temps.items()):\n",
    "        model_name, pretrained_dset = model_legend.split(';')\n",
    "        model, _, preprocess = open_clip.create_model_and_transforms(model_name,\n",
    "            pretrained=pretrained_dset,\n",
    "            device=device)\n",
    "        tokenizer = open_clip.get_tokenizer(model_name)\n",
    "        if isinstance(dset, torch.utils.data.dataset.Subset):\n",
    "            dset.dataset.transform = preprocess\n",
    "        else:\n",
    "            dset.transform = preprocess\n",
    "        _ , templates = get_openai_prompts(dataset_name)\n",
    "\n",
    "        template_eces = []\n",
    "        image_features, actual = get_image_features(\n",
    "            model,  dset,  batch_size=batch_size, device=device\n",
    "        )\n",
    "        for text_template in templates:\n",
    "            #predictions, actual, probs = get_preds(model, tokenizer, dset, \n",
    "            #    text_template=text_template, temp_scaling=temp, device=device)\n",
    "\n",
    "            predictions, probs = get_preds_from_img_features(model, tokenizer, dset, image_features, text_template=text_template, \n",
    "                #temp_scaling=temp,\n",
    "                device = device)\n",
    "\n",
    "            ECE, _, acc = get_metrics(predictions, actual, probs)\n",
    "            template_eces.append(ECE)\n",
    "        \n",
    "        model_eces[model_legend] = template_eces\n",
    "    dataset_eces_uncalib[dataset_name] = model_eces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ViT-B-16;laion2b_s34b_b88k</th>\n",
       "      <th>ViT-L-14;laion2b_s32b_b82k</th>\n",
       "      <th>ViT-B-32;laion2b_s34b_b79k</th>\n",
       "      <th>ViT-B-16;openai</th>\n",
       "      <th>ViT-L-14;openai</th>\n",
       "      <th>ViT-B-32;openai</th>\n",
       "      <th>ViT-B-16;laion400m_e31</th>\n",
       "      <th>ViT-L-14;laion400m_e31</th>\n",
       "      <th>ViT-B-32;laion400m_e31</th>\n",
       "      <th>RN50;openai</th>\n",
       "      <th>RN50;yfcc15m</th>\n",
       "      <th>RN50;cc12m</th>\n",
       "      <th>ViT-H-14;laion2b_s32b_b79k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.122836</td>\n",
       "      <td>0.086431</td>\n",
       "      <td>0.087813</td>\n",
       "      <td>0.036334</td>\n",
       "      <td>0.033818</td>\n",
       "      <td>0.059862</td>\n",
       "      <td>0.202099</td>\n",
       "      <td>0.185898</td>\n",
       "      <td>0.086632</td>\n",
       "      <td>0.050418</td>\n",
       "      <td>0.408229</td>\n",
       "      <td>0.457522</td>\n",
       "      <td>0.115604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.069736</td>\n",
       "      <td>0.066610</td>\n",
       "      <td>0.047297</td>\n",
       "      <td>0.017577</td>\n",
       "      <td>0.033505</td>\n",
       "      <td>0.033248</td>\n",
       "      <td>0.173579</td>\n",
       "      <td>0.161802</td>\n",
       "      <td>0.064108</td>\n",
       "      <td>0.019249</td>\n",
       "      <td>0.399920</td>\n",
       "      <td>0.499599</td>\n",
       "      <td>0.078794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.174676</td>\n",
       "      <td>0.142697</td>\n",
       "      <td>0.157267</td>\n",
       "      <td>0.068098</td>\n",
       "      <td>0.094792</td>\n",
       "      <td>0.054122</td>\n",
       "      <td>0.253087</td>\n",
       "      <td>0.278839</td>\n",
       "      <td>0.190717</td>\n",
       "      <td>0.070385</td>\n",
       "      <td>0.482612</td>\n",
       "      <td>0.544304</td>\n",
       "      <td>0.144831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.114273</td>\n",
       "      <td>0.098387</td>\n",
       "      <td>0.098266</td>\n",
       "      <td>0.054807</td>\n",
       "      <td>0.063350</td>\n",
       "      <td>0.052947</td>\n",
       "      <td>0.237552</td>\n",
       "      <td>0.224304</td>\n",
       "      <td>0.150537</td>\n",
       "      <td>0.051470</td>\n",
       "      <td>0.468888</td>\n",
       "      <td>0.552707</td>\n",
       "      <td>0.122922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.109129</td>\n",
       "      <td>0.085733</td>\n",
       "      <td>0.092141</td>\n",
       "      <td>0.033498</td>\n",
       "      <td>0.039680</td>\n",
       "      <td>0.046459</td>\n",
       "      <td>0.191665</td>\n",
       "      <td>0.219530</td>\n",
       "      <td>0.092844</td>\n",
       "      <td>0.052139</td>\n",
       "      <td>0.465253</td>\n",
       "      <td>0.455235</td>\n",
       "      <td>0.117295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.057849</td>\n",
       "      <td>0.074522</td>\n",
       "      <td>0.048563</td>\n",
       "      <td>0.046292</td>\n",
       "      <td>0.027296</td>\n",
       "      <td>0.034127</td>\n",
       "      <td>0.179664</td>\n",
       "      <td>0.194068</td>\n",
       "      <td>0.084525</td>\n",
       "      <td>0.032639</td>\n",
       "      <td>0.453192</td>\n",
       "      <td>0.519510</td>\n",
       "      <td>0.084776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.170753</td>\n",
       "      <td>0.157615</td>\n",
       "      <td>0.157100</td>\n",
       "      <td>0.064558</td>\n",
       "      <td>0.089233</td>\n",
       "      <td>0.057797</td>\n",
       "      <td>0.299769</td>\n",
       "      <td>0.294726</td>\n",
       "      <td>0.187019</td>\n",
       "      <td>0.054727</td>\n",
       "      <td>0.550923</td>\n",
       "      <td>0.559180</td>\n",
       "      <td>0.133394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.097127</td>\n",
       "      <td>0.096349</td>\n",
       "      <td>0.104054</td>\n",
       "      <td>0.035263</td>\n",
       "      <td>0.044863</td>\n",
       "      <td>0.053665</td>\n",
       "      <td>0.242807</td>\n",
       "      <td>0.253109</td>\n",
       "      <td>0.150434</td>\n",
       "      <td>0.038144</td>\n",
       "      <td>0.509828</td>\n",
       "      <td>0.579766</td>\n",
       "      <td>0.145595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ViT-B-16;laion2b_s34b_b88k  ViT-L-14;laion2b_s32b_b82k  \\\n",
       "0                    0.122836                    0.086431   \n",
       "1                    0.069736                    0.066610   \n",
       "2                    0.174676                    0.142697   \n",
       "3                    0.114273                    0.098387   \n",
       "4                    0.109129                    0.085733   \n",
       "5                    0.057849                    0.074522   \n",
       "6                    0.170753                    0.157615   \n",
       "7                    0.097127                    0.096349   \n",
       "\n",
       "   ViT-B-32;laion2b_s34b_b79k  ViT-B-16;openai  ViT-L-14;openai  \\\n",
       "0                    0.087813         0.036334         0.033818   \n",
       "1                    0.047297         0.017577         0.033505   \n",
       "2                    0.157267         0.068098         0.094792   \n",
       "3                    0.098266         0.054807         0.063350   \n",
       "4                    0.092141         0.033498         0.039680   \n",
       "5                    0.048563         0.046292         0.027296   \n",
       "6                    0.157100         0.064558         0.089233   \n",
       "7                    0.104054         0.035263         0.044863   \n",
       "\n",
       "   ViT-B-32;openai  ViT-B-16;laion400m_e31  ViT-L-14;laion400m_e31  \\\n",
       "0         0.059862                0.202099                0.185898   \n",
       "1         0.033248                0.173579                0.161802   \n",
       "2         0.054122                0.253087                0.278839   \n",
       "3         0.052947                0.237552                0.224304   \n",
       "4         0.046459                0.191665                0.219530   \n",
       "5         0.034127                0.179664                0.194068   \n",
       "6         0.057797                0.299769                0.294726   \n",
       "7         0.053665                0.242807                0.253109   \n",
       "\n",
       "   ViT-B-32;laion400m_e31  RN50;openai  RN50;yfcc15m  RN50;cc12m  \\\n",
       "0                0.086632     0.050418      0.408229    0.457522   \n",
       "1                0.064108     0.019249      0.399920    0.499599   \n",
       "2                0.190717     0.070385      0.482612    0.544304   \n",
       "3                0.150537     0.051470      0.468888    0.552707   \n",
       "4                0.092844     0.052139      0.465253    0.455235   \n",
       "5                0.084525     0.032639      0.453192    0.519510   \n",
       "6                0.187019     0.054727      0.550923    0.559180   \n",
       "7                0.150434     0.038144      0.509828    0.579766   \n",
       "\n",
       "   ViT-H-14;laion2b_s32b_b79k  \n",
       "0                    0.115604  \n",
       "1                    0.078794  \n",
       "2                    0.144831  \n",
       "3                    0.122922  \n",
       "4                    0.117295  \n",
       "5                    0.084776  \n",
       "6                    0.133394  \n",
       "7                    0.145595  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(dataset_eces_uncalib['DTD'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_features, actual = get_image_features(model, imagenet_test, batch_size=128,\n",
    "        device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual = torch.IntTensor(actual).to(device).long()\n",
    "actual.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_mapping = map_imagenet_to_readable_label()\n",
    "imagenet_test.classes = [imagenet_mapping[x] for x in imagenet_test.classes ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = tokenizer([text_template.replace('{}',x) for x in imagenet_test.classes])\n",
    "with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "    text_features = model.encode_text(text.to(device))\n",
    "    text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "    \n",
    "text_probs = (100.0 * image_features @ text_features.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6131701469421387"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Setup LBGFS\n",
    "temperature = nn.Parameter((torch.ones(1)).to(device))\n",
    "args = {'temperature': temperature}\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Removing strong_wolfe line search results in jump after 50 epochs\n",
    "optimizer = optim.LBFGS([temperature], lr=0.001, max_iter=1000, line_search_fn='strong_wolfe')\n",
    "\n",
    "temps = []\n",
    "losses = []\n",
    "def _eval():\n",
    "    loss = criterion(T_scaling(text_probs, args), actual)\n",
    "    loss.backward()\n",
    "    temps.append(temperature.item())\n",
    "    losses.append(loss)\n",
    "    return loss\n",
    "optimizer.step(_eval)\n",
    "temperature.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.620787089606212, 0.958984375, 0.0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions, probs = get_preds_from_img_features(\n",
    "    model, tokenizer, imagenet_test, image_features, text_template=text_template, temp_scaling=temperature.item(), device = device\n",
    ")\n",
    "get_metrics(predictions, actual, probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.025181555526703616, 0.057354552355015076, 0.7139)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cifar_test, num_classes = get_test_set('CIFAR100', preprocess)\n",
    "predictions, actual, probs = get_preds(model, tokenizer, cifar_test, \n",
    "    text_template=text_template, temp_scaling=temperature.item(), device=device)\n",
    "get_metrics(predictions, actual, probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.007352347984910052, 0.18847142159938812, 0.9174)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cifar_test, num_classes = get_test_set('CIFAR10', preprocess)\n",
    "predictions, actual, probs = get_preds(model, tokenizer, cifar_test, \n",
    "    text_template=text_template, temp_scaling=temperature.item(), device=device)\n",
    "get_metrics(predictions, actual, probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "content_understanding",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6d36b139402f0f8909133622e5e80cdd43397350f551386f6df555aa508ab69d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
