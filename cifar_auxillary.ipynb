{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/content_understanding/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import open_clip\n",
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "from PIL import Image\n",
    "import open_clip\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from sklearn import calibration\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.tree import DecisionTreeRegressor as DT\n",
    "from sklearn.isotonic import IsotonicRegression as IR\n",
    "from scipy.stats import norm\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'ViT-B-16'\n",
    "pretrained_dset = 'laion400m_e31'\n",
    "\n",
    "model, _, preprocess = open_clip.create_model_and_transforms(model_name,\n",
    "    pretrained=pretrained_dset,\n",
    "    device=device)\n",
    "tokenizer = open_clip.get_tokenizer(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_test = datasets.ImageFolder(f'/home/ubuntu/data/Imagenet/ILSVRC/Data/CLS-LOC/train/', transform=preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:18<00:00, 12.74it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_template = 'a photo of a {}.'\n",
    "np.random.seed(0)\n",
    "\n",
    "subset_in_classes = []\n",
    "for c in tqdm(range(len(imagenet_test.classes))):\n",
    "    appending = np.random.choice(np.where(np.array(imagenet_test.targets) == c)[0], 50, replace=False)\n",
    "    subset_in_classes.extend(appending.tolist())\n",
    "subset = torch.utils.data.Subset(imagenet_test, subset_in_classes)\n",
    "subset.classes = imagenet_test.classes\n",
    "imagenet_test = subset\n",
    "len(imagenet_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_to_consider = [\n",
    "    ('ViT-B-16' , 'laion2b_s34b_b88k'),\n",
    "    ('ViT-L-14' , 'laion2b_s32b_b82k'),\n",
    "    ('ViT-B-32' , 'laion2b_s34b_b79k'),\n",
    "\n",
    "    ('ViT-B-16' , 'openai'),\n",
    "    ('ViT-L-14' , 'openai'),\n",
    "    ('ViT-B-32' , 'openai'),\n",
    "\n",
    "    ('ViT-B-16' , 'laion400m_e31'),\n",
    "    ('ViT-L-14' , 'laion400m_e31'),\n",
    "    ('ViT-B-32' , 'laion400m_e31'),\n",
    "\n",
    "    ('RN50', 'openai'),\n",
    "    ('RN50', 'yfcc15m'),\n",
    "    ('RN50', 'cc12m'),\n",
    "\n",
    "    ('ViT-H-14', 'laion2b_s32b_b79k')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [32:24<00:00, 149.58s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ViT-B-16;laion2b_s34b_b88k': 1.2636255025863647,\n",
       " 'ViT-L-14;laion2b_s32b_b82k': 1.269670009613037,\n",
       " 'ViT-B-32;laion2b_s34b_b79k': 1.2540593147277832,\n",
       " 'ViT-B-16;openai': 0.7175883650779724,\n",
       " 'ViT-L-14;openai': 0.7447569966316223,\n",
       " 'ViT-B-32;openai': 0.6858727335929871,\n",
       " 'ViT-B-16;laion400m_e31': 1.5263614654541016,\n",
       " 'ViT-L-14;laion400m_e31': 1.6955595016479492,\n",
       " 'ViT-B-32;laion400m_e31': 1.2037781476974487,\n",
       " 'RN50;openai': 0.7391236424446106,\n",
       " 'RN50;yfcc15m': 2.5977625846862793,\n",
       " 'RN50;cc12m': 2.781331777572632,\n",
       " 'ViT-H-14;laion2b_s32b_b79k': 1.3318419456481934}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#imagenet_mapping = map_imagenet_to_readable_label()\n",
    "#imagenet_test.classes = [imagenet_mapping[x] for x in imagenet_test.classes ]\n",
    "\n",
    "cifar_val = datasets.CIFAR100('/home/ubuntu/data/', train = True, transform = None, download=True)\n",
    "classes , templates = get_openai_prompts('CIFAR100')\n",
    "text_template = templates[5]\n",
    "all_temps = {}\n",
    "for model_name, pretrained_dset in tqdm(models_to_consider):\n",
    "    model, _, preprocess = open_clip.create_model_and_transforms(model_name,\n",
    "        pretrained=pretrained_dset,\n",
    "        device=device)\n",
    "    tokenizer = open_clip.get_tokenizer(model_name)\n",
    "    cifar_val.transform = preprocess\n",
    "    cifar_val.classes = classes\n",
    "\n",
    "    image_features, actual = get_image_features(model, cifar_val, batch_size=128,\n",
    "        device = device)\n",
    "\n",
    "    actual = torch.IntTensor(actual).to(device).long()\n",
    "\n",
    "    text = tokenizer([text_template.replace('{}',x) for x in cifar_val.classes])\n",
    "    with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "        text_features = model.encode_text(text.to(device))\n",
    "        text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "        \n",
    "    text_probs = (100.0 * image_features @ text_features.T)\n",
    "\n",
    "    ## Setup LBGFS\n",
    "    temperature = nn.Parameter((torch.ones(1)).to(device))\n",
    "    args = {'temperature': temperature}\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Removing strong_wolfe line search results in jump after 50 epochs\n",
    "    optimizer = optim.LBFGS([temperature], lr=0.001, max_iter=1000, line_search_fn='strong_wolfe')\n",
    "\n",
    "    temps = []\n",
    "    losses = []\n",
    "    def _eval():\n",
    "        loss = criterion(T_scaling(text_probs, args), actual)\n",
    "        loss.backward()\n",
    "        temps.append(temperature.item())\n",
    "        losses.append(loss)\n",
    "        return loss\n",
    "    optimizer.step(_eval)\n",
    "    all_temps[model_name+';' + pretrained_dset] = temperature.item()\n",
    "all_temps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imagenet</th>\n",
       "      <th>cifar100</th>\n",
       "      <th>cifaro100 a bad photo of a {}.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ViT-B-16;laion2b_s34b_b88k</th>\n",
       "      <td>1.387834</td>\n",
       "      <td>1.253799</td>\n",
       "      <td>1.263626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ViT-L-14;laion2b_s32b_b82k</th>\n",
       "      <td>1.412957</td>\n",
       "      <td>1.268503</td>\n",
       "      <td>1.269670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ViT-B-32;laion2b_s34b_b79k</th>\n",
       "      <td>1.409250</td>\n",
       "      <td>1.307964</td>\n",
       "      <td>1.254059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ViT-B-16;openai</th>\n",
       "      <td>0.982526</td>\n",
       "      <td>0.716199</td>\n",
       "      <td>0.717588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ViT-L-14;openai</th>\n",
       "      <td>1.027355</td>\n",
       "      <td>0.722536</td>\n",
       "      <td>0.744757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ViT-B-32;openai</th>\n",
       "      <td>0.978916</td>\n",
       "      <td>0.740836</td>\n",
       "      <td>0.685873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ViT-B-16;laion400m_e31</th>\n",
       "      <td>1.613170</td>\n",
       "      <td>1.501032</td>\n",
       "      <td>1.526361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ViT-L-14;laion400m_e31</th>\n",
       "      <td>1.753757</td>\n",
       "      <td>1.686527</td>\n",
       "      <td>1.695560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ViT-B-32;laion400m_e31</th>\n",
       "      <td>1.372426</td>\n",
       "      <td>1.239664</td>\n",
       "      <td>1.203778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RN50;openai</th>\n",
       "      <td>0.974209</td>\n",
       "      <td>0.706719</td>\n",
       "      <td>0.739124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RN50;yfcc15m</th>\n",
       "      <td>2.565150</td>\n",
       "      <td>2.858851</td>\n",
       "      <td>2.597763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RN50;cc12m</th>\n",
       "      <td>2.662893</td>\n",
       "      <td>2.668366</td>\n",
       "      <td>2.781332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ViT-H-14;laion2b_s32b_b79k</th>\n",
       "      <td>1.511935</td>\n",
       "      <td>1.331027</td>\n",
       "      <td>1.331842</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            imagenet  cifar100  cifaro100 a bad photo of a {}.\n",
       "ViT-B-16;laion2b_s34b_b88k  1.387834  1.253799                        1.263626\n",
       "ViT-L-14;laion2b_s32b_b82k  1.412957  1.268503                        1.269670\n",
       "ViT-B-32;laion2b_s34b_b79k  1.409250  1.307964                        1.254059\n",
       "ViT-B-16;openai             0.982526  0.716199                        0.717588\n",
       "ViT-L-14;openai             1.027355  0.722536                        0.744757\n",
       "ViT-B-32;openai             0.978916  0.740836                        0.685873\n",
       "ViT-B-16;laion400m_e31      1.613170  1.501032                        1.526361\n",
       "ViT-L-14;laion400m_e31      1.753757  1.686527                        1.695560\n",
       "ViT-B-32;laion400m_e31      1.372426  1.239664                        1.203778\n",
       "RN50;openai                 0.974209  0.706719                        0.739124\n",
       "RN50;yfcc15m                2.565150  2.858851                        2.597763\n",
       "RN50;cc12m                  2.662893  2.668366                        2.781332\n",
       "ViT-H-14;laion2b_s32b_b79k  1.511935  1.331027                        1.331842"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = {'ViT-B-16;laion2b_s34b_b88k': 1.3878337144851685,\n",
    " 'ViT-L-14;laion2b_s32b_b82k': 1.4129570722579956,\n",
    " 'ViT-B-32;laion2b_s34b_b79k': 1.4092495441436768,\n",
    " 'ViT-B-16;openai': 0.9825258851051331,\n",
    " 'ViT-L-14;openai': 1.0273551940917969,\n",
    " 'ViT-B-32;openai': 0.9789162874221802,\n",
    " 'ViT-B-16;laion400m_e31': 1.6131701469421387,\n",
    " 'ViT-L-14;laion400m_e31': 1.7537566423416138,\n",
    " 'ViT-B-32;laion400m_e31': 1.37242591381073,\n",
    " 'RN50;openai': 0.9742085933685303,\n",
    " 'RN50;yfcc15m': 2.5651497840881348,\n",
    " 'RN50;cc12m': 2.662893295288086,\n",
    " 'ViT-H-14;laion2b_s32b_b79k': 1.5119352340698242}\n",
    "b = {'ViT-B-16;laion2b_s34b_b88k': 1.253799319267273,\n",
    " 'ViT-L-14;laion2b_s32b_b82k': 1.2685033082962036,\n",
    " 'ViT-B-32;laion2b_s34b_b79k': 1.3079637289047241,\n",
    " 'ViT-B-16;openai': 0.7161993384361267,\n",
    " 'ViT-L-14;openai': 0.7225357890129089,\n",
    " 'ViT-B-32;openai': 0.7408358454704285,\n",
    " 'ViT-B-16;laion400m_e31': 1.5010323524475098,\n",
    " 'ViT-L-14;laion400m_e31': 1.6865270137786865,\n",
    " 'ViT-B-32;laion400m_e31': 1.23966383934021,\n",
    " 'RN50;openai': 0.7067190408706665,\n",
    " 'RN50;yfcc15m': 2.858851432800293,\n",
    " 'RN50;cc12m': 2.6683664321899414,\n",
    " 'ViT-H-14;laion2b_s32b_b79k': 1.3310267925262451}\n",
    "\n",
    "from collections import defaultdict\n",
    "res = defaultdict(list)\n",
    "for k in a:\n",
    "    res[k] = [a[k], b[k], all_temps[k]]\n",
    "\n",
    "pd.DataFrame(res).transpose().rename(columns={0:'imagenet', 1:'cifar100',2: f\"cifaro100 {text_template}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "cifar100, _ = get_test_set('CIFAR100', preprocess)\n",
    "cifar10, _ = get_test_set('CIFAR10', preprocess)\n",
    "#sun_dset = datasets.LSUN(root=f'/home/ubuntu/data/LSUN', classes='test', transform=preprocess)\n",
    "food_dset = datasets.Food101('/home/ubuntu/data/Food101/', split='test', transform=preprocess,download=True)\n",
    "#sun_dset = datasets.SUN397()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [06:40<00:00, 30.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [06:38<00:00, 30.66s/it]\n",
      "100%|██████████| 13/13 [14:19<00:00, 66.15s/it]\n"
     ]
    }
   ],
   "source": [
    "dataset_eces = {}\n",
    "dataset_accs = {}\n",
    "for dataset_name in ['CIFAR100', 'CIFAR10', 'Food101', 'SUN397']:\n",
    "    dset,_ = get_test_set(dataset_name, None)\n",
    "    model_eces = {}\n",
    "    model_accs = {}\n",
    "    for model_legend, temp in tqdm(all_temps.items()):\n",
    "        model_name, pretrained_dset = model_legend.split(';')\n",
    "        model, _, preprocess = open_clip.create_model_and_transforms(model_name,\n",
    "            pretrained=pretrained_dset,\n",
    "            device=device)\n",
    "        tokenizer = open_clip.get_tokenizer(model_name)\n",
    "        dset.transform = preprocess\n",
    "        _ , templates = get_openai_prompts(dataset_name)\n",
    "\n",
    "        template_eces = []\n",
    "        template_accs = []\n",
    "        image_features, actual = get_image_features(\n",
    "            model,  dset,  batch_size=batch_size, device=device\n",
    "        )\n",
    "        for text_template in templates:\n",
    "            #predictions, actual, probs = get_preds(model, tokenizer, dset, \n",
    "            #    text_template=text_template, temp_scaling=temp, device=device)\n",
    "\n",
    "            predictions, probs = get_preds_from_img_features(model, tokenizer, dset, image_features, text_template=text_template, temp_scaling=temp,\n",
    "                device = device)\n",
    "\n",
    "            ECE, _, acc = get_metrics(predictions, actual, probs)\n",
    "            template_eces.append(ECE)\n",
    "            template_accs.append(acc)\n",
    "        \n",
    "        model_eces[model_legend] = template_eces\n",
    "        model_accs[model_legend] = template_accs\n",
    "    dataset_eces[dataset_name] = model_eces\n",
    "    dataset_accs[dataset_name] = model_eces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ViT-B-16;laion2b_s34b_b88k</th>\n",
       "      <th>ViT-L-14;laion2b_s32b_b82k</th>\n",
       "      <th>ViT-B-32;laion2b_s34b_b79k</th>\n",
       "      <th>ViT-B-16;openai</th>\n",
       "      <th>ViT-L-14;openai</th>\n",
       "      <th>ViT-B-32;openai</th>\n",
       "      <th>ViT-B-16;laion400m_e31</th>\n",
       "      <th>ViT-L-14;laion400m_e31</th>\n",
       "      <th>ViT-B-32;laion400m_e31</th>\n",
       "      <th>RN50;openai</th>\n",
       "      <th>RN50;yfcc15m</th>\n",
       "      <th>RN50;cc12m</th>\n",
       "      <th>ViT-H-14;laion2b_s32b_b79k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.028102</td>\n",
       "      <td>0.014133</td>\n",
       "      <td>0.015249</td>\n",
       "      <td>0.031657</td>\n",
       "      <td>0.041401</td>\n",
       "      <td>0.025413</td>\n",
       "      <td>0.024479</td>\n",
       "      <td>0.010244</td>\n",
       "      <td>0.027594</td>\n",
       "      <td>0.034527</td>\n",
       "      <td>0.135337</td>\n",
       "      <td>0.100776</td>\n",
       "      <td>0.013398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.046665</td>\n",
       "      <td>0.029012</td>\n",
       "      <td>0.049906</td>\n",
       "      <td>0.057445</td>\n",
       "      <td>0.039721</td>\n",
       "      <td>0.051354</td>\n",
       "      <td>0.040410</td>\n",
       "      <td>0.015074</td>\n",
       "      <td>0.063761</td>\n",
       "      <td>0.067796</td>\n",
       "      <td>0.135968</td>\n",
       "      <td>0.089820</td>\n",
       "      <td>0.027745</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ViT-B-16;laion2b_s34b_b88k  ViT-L-14;laion2b_s32b_b82k  \\\n",
       "0                    0.028102                    0.014133   \n",
       "1                    0.046665                    0.029012   \n",
       "\n",
       "   ViT-B-32;laion2b_s34b_b79k  ViT-B-16;openai  ViT-L-14;openai  \\\n",
       "0                    0.015249         0.031657         0.041401   \n",
       "1                    0.049906         0.057445         0.039721   \n",
       "\n",
       "   ViT-B-32;openai  ViT-B-16;laion400m_e31  ViT-L-14;laion400m_e31  \\\n",
       "0         0.025413                0.024479                0.010244   \n",
       "1         0.051354                0.040410                0.015074   \n",
       "\n",
       "   ViT-B-32;laion400m_e31  RN50;openai  RN50;yfcc15m  RN50;cc12m  \\\n",
       "0                0.027594     0.034527      0.135337    0.100776   \n",
       "1                0.063761     0.067796      0.135968    0.089820   \n",
       "\n",
       "   ViT-H-14;laion2b_s32b_b79k  \n",
       "0                    0.013398  \n",
       "1                    0.027745  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_eces_supervised = {}\n",
    "dataset_accs_supervised = {}\n",
    "for dataset_name in ['CIFAR100', 'CIFAR10', 'Food101', 'SUN397']:\n",
    "    dset,_ = get_test_set(dataset_name, None)\n",
    "    model_eces = {}\n",
    "    model_accs = {}\n",
    "    for model_legend, temp in tqdm(all_temps.items()):\n",
    "        model_name, pretrained_dset = model_legend.split(';')\n",
    "        model, _, preprocess = open_clip.create_model_and_transforms(model_name,\n",
    "            pretrained=pretrained_dset,\n",
    "            device=device)\n",
    "        tokenizer = open_clip.get_tokenizer(model_name)\n",
    "        if isinstance(dset, torch.utils.data.dataset.Subset):\n",
    "            dset.dataset.transform = preprocess\n",
    "        else:\n",
    "            dset.transform = preprocess\n",
    "        _ , templates = get_openai_prompts(dataset_name)\n",
    "\n",
    "        template_eces = []\n",
    "        template_accs = []\n",
    "        image_features, actual = get_image_features(\n",
    "            model,  dset,  batch_size=batch_size, device=device\n",
    "        )\n",
    "        for text_template in templates:\n",
    "            #predictions, actual, probs = get_preds(model, tokenizer, dset, \n",
    "            #    text_template=text_template, temp_scaling=temp, device=device)\n",
    "\n",
    "            predictions, probs = get_preds_from_img_features(model, tokenizer, dset, image_features, text_template=text_template, temp_scaling=temp,\n",
    "                device = device)\n",
    "\n",
    "            ECE, _, acc = get_metrics(predictions, actual, probs)\n",
    "            template_eces.append(ECE)\n",
    "            template_accs.append(acc)\n",
    "        \n",
    "        model_eces[model_legend] = template_eces\n",
    "        model_accs[model_legend] = template_accs\n",
    "    dataset_eces_supervised[dataset_name] = model_eces\n",
    "    dataset_accs_supervised[dataset_name] = model_eces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "a photo of a {}.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((0.06008501325334824, 0.19970703125, 0.9174),\n",
       " (0.034525964367322824, 0.19967076182365417, 0.9175))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_legend =  'ViT-B-16;laion400m_e31'\n",
    "model_name, pretrained_dset = model_legend.split(';')\n",
    "model, _, preprocess = open_clip.create_model_and_transforms(model_name,\n",
    "            pretrained=pretrained_dset,\n",
    "            device=device)\n",
    "tokenizer = open_clip.get_tokenizer(model_name)\n",
    "dset,_ = get_test_set('CIFAR10', preprocess)\n",
    "_ , templates = get_openai_prompts('CIFAR10')\n",
    "print(templates[0])\n",
    "image_features, actual = get_image_features(\n",
    "        model,  dset,  batch_size=batch_size, device=device\n",
    "    )\n",
    "predictions, probs = get_preds_from_img_features(model, tokenizer, dset, image_features, text_template=templates[0], \n",
    "        #temp_scaling=temp,\n",
    "        device = device)\n",
    "predictions_, actual_, probs_ = get_preds(model, tokenizer, dset, text_template=templates[0], device=device)\n",
    "get_metrics(predictions, actual, probs), get_metrics(predictions_, actual_, probs_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [06:52<00:00, 31.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ViT-B-16;laion2b_s34b_b88k  ViT-L-14;laion2b_s32b_b82k  \\\n",
      "0                     0.058503                    0.045934   \n",
      "1                     0.045820                    0.038335   \n",
      "2                     0.060482                    0.039551   \n",
      "3                     0.059873                    0.049759   \n",
      "4                     0.066750                    0.043859   \n",
      "5                     0.062486                    0.050213   \n",
      "6                     0.062093                    0.053934   \n",
      "7                     0.053304                    0.045275   \n",
      "8                     0.069938                    0.057849   \n",
      "9                     0.048214                    0.046141   \n",
      "10                    0.040250                    0.036563   \n",
      "11                    0.053200                    0.037751   \n",
      "12                    0.061325                    0.051173   \n",
      "13                    0.063761                    0.046218   \n",
      "14                    0.054451                    0.048778   \n",
      "15                    0.053151                    0.046896   \n",
      "16                    0.045382                    0.040281   \n",
      "17                    0.068705                    0.056568   \n",
      "\n",
      "    ViT-B-32;laion2b_s34b_b79k  ViT-B-16;openai  ViT-L-14;openai  \\\n",
      "0                     0.072348         0.121402         0.117865   \n",
      "1                     0.050802         0.095473         0.102713   \n",
      "2                     0.064510         0.071126         0.113897   \n",
      "3                     0.066378         0.108485         0.078968   \n",
      "4                     0.071112         0.099207         0.075937   \n",
      "5                     0.064337         0.114293         0.105366   \n",
      "6                     0.068780         0.108451         0.100493   \n",
      "7                     0.072023         0.130645         0.143433   \n",
      "8                     0.090431         0.106683         0.116753   \n",
      "9                     0.068185         0.148774         0.141616   \n",
      "10                    0.042161         0.120829         0.123818   \n",
      "11                    0.063971         0.100871         0.111189   \n",
      "12                    0.061481         0.139785         0.103225   \n",
      "13                    0.070204         0.127696         0.105246   \n",
      "14                    0.053712         0.136247         0.146812   \n",
      "15                    0.055417         0.135310         0.128102   \n",
      "16                    0.059387         0.166664         0.167992   \n",
      "17                    0.072097         0.140142         0.137583   \n",
      "\n",
      "    ViT-B-32;openai  ViT-B-16;laion400m_e31  ViT-L-14;laion400m_e31  \\\n",
      "0          0.110404                0.102299                0.110380   \n",
      "1          0.091311                0.104224                0.093059   \n",
      "2          0.069233                0.110759                0.093130   \n",
      "3          0.090336                0.108625                0.101925   \n",
      "4          0.050484                0.116391                0.102179   \n",
      "5          0.126630                0.109870                0.107615   \n",
      "6          0.116463                0.114862                0.110457   \n",
      "7          0.129102                0.105153                0.111899   \n",
      "8          0.120098                0.125752                0.132232   \n",
      "9          0.151651                0.104212                0.118815   \n",
      "10         0.135985                0.102549                0.095930   \n",
      "11         0.105480                0.107702                0.101679   \n",
      "12         0.121141                0.106990                0.115826   \n",
      "13         0.087463                0.116002                0.110639   \n",
      "14         0.171092                0.111427                0.118801   \n",
      "15         0.149140                0.108083                0.114800   \n",
      "16         0.160490                0.100842                0.112267   \n",
      "17         0.128236                0.140139                0.157272   \n",
      "\n",
      "    ViT-B-32;laion400m_e31  RN50;openai  RN50;yfcc15m  RN50;cc12m  \\\n",
      "0                 0.076371     0.117191      0.392679    0.389912   \n",
      "1                 0.077769     0.087233      0.337625    0.383807   \n",
      "2                 0.078300     0.042404      0.409148    0.363756   \n",
      "3                 0.078433     0.078704      0.597304    0.333214   \n",
      "4                 0.085470     0.058768      0.530208    0.385945   \n",
      "5                 0.065901     0.101383      0.342650    0.375240   \n",
      "6                 0.072624     0.104138      0.378823    0.383190   \n",
      "7                 0.067994     0.112516      0.448670    0.325035   \n",
      "8                 0.082396     0.113385      0.427107    0.400563   \n",
      "9                 0.067266     0.123492      0.429011    0.418346   \n",
      "10                0.067955     0.107606      0.339653    0.366755   \n",
      "11                0.071075     0.065681      0.426691    0.320966   \n",
      "12                0.064783     0.090253      0.487545    0.345652   \n",
      "13                0.074718     0.088024      0.429599    0.394679   \n",
      "14                0.053929     0.111538      0.367622    0.384283   \n",
      "15                0.061849     0.101622      0.392982    0.389252   \n",
      "16                0.049667     0.128980      0.413619    0.338823   \n",
      "17                0.062791     0.113888      0.453722    0.450011   \n",
      "\n",
      "    ViT-H-14;laion2b_s32b_b79k  \n",
      "0                     0.053100  \n",
      "1                     0.045346  \n",
      "2                     0.047010  \n",
      "3                     0.052364  \n",
      "4                     0.054513  \n",
      "5                     0.055070  \n",
      "6                     0.057776  \n",
      "7                     0.043528  \n",
      "8                     0.068385  \n",
      "9                     0.050647  \n",
      "10                    0.050975  \n",
      "11                    0.044438  \n",
      "12                    0.052352  \n",
      "13                    0.053711  \n",
      "14                    0.054190  \n",
      "15                    0.056108  \n",
      "16                    0.054723  \n",
      "17                    0.072643  \n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [06:47<00:00, 31.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ViT-B-16;laion2b_s34b_b88k  ViT-L-14;laion2b_s32b_b82k  \\\n",
      "0                     0.010584                    0.007821   \n",
      "1                     0.003846                    0.004197   \n",
      "2                     0.007205                    0.003622   \n",
      "3                     0.011140                    0.007182   \n",
      "4                     0.009263                    0.006535   \n",
      "5                     0.012927                    0.006660   \n",
      "6                     0.009915                    0.006664   \n",
      "7                     0.015371                    0.009377   \n",
      "8                     0.013392                    0.028946   \n",
      "9                     0.008501                    0.007654   \n",
      "10                    0.002923                    0.004935   \n",
      "11                    0.006695                    0.005682   \n",
      "12                    0.011906                    0.004308   \n",
      "13                    0.009057                    0.004868   \n",
      "14                    0.010353                    0.006806   \n",
      "15                    0.008436                    0.007017   \n",
      "16                    0.014519                    0.008805   \n",
      "17                    0.027452                    0.008615   \n",
      "\n",
      "    ViT-B-32;laion2b_s34b_b79k  ViT-B-16;openai  ViT-L-14;openai  \\\n",
      "0                     0.015267         0.052941         0.048764   \n",
      "1                     0.011603         0.053788         0.053379   \n",
      "2                     0.014839         0.029693         0.039435   \n",
      "3                     0.012595         0.049254         0.037289   \n",
      "4                     0.013023         0.040622         0.033968   \n",
      "5                     0.015577         0.058721         0.055635   \n",
      "6                     0.015433         0.069264         0.052584   \n",
      "7                     0.023952         0.045648         0.058676   \n",
      "8                     0.025949         0.087799         0.101489   \n",
      "9                     0.015310         0.063762         0.076234   \n",
      "10                    0.007500         0.064879         0.057954   \n",
      "11                    0.012888         0.049141         0.065425   \n",
      "12                    0.012587         0.068466         0.059436   \n",
      "13                    0.013329         0.060841         0.054055   \n",
      "14                    0.011432         0.058770         0.078196   \n",
      "15                    0.012720         0.075765         0.075881   \n",
      "16                    0.023213         0.064193         0.079541   \n",
      "17                    0.020180         0.126186         0.120056   \n",
      "\n",
      "    ViT-B-32;openai  ViT-B-16;laion400m_e31  ViT-L-14;laion400m_e31  \\\n",
      "0          0.049213                0.034623                0.028494   \n",
      "1          0.040932                0.032706                0.021722   \n",
      "2          0.021482                0.029398                0.024675   \n",
      "3          0.041575                0.034543                0.026291   \n",
      "4          0.012795                0.029764                0.027248   \n",
      "5          0.071265                0.039498                0.027768   \n",
      "6          0.057652                0.036106                0.031694   \n",
      "7          0.044401                0.046037                0.036159   \n",
      "8          0.088463                0.036386                0.035079   \n",
      "9          0.078749                0.035678                0.034645   \n",
      "10         0.078691                0.033514                0.022363   \n",
      "11         0.050637                0.035034                0.027535   \n",
      "12         0.065203                0.032993                0.029294   \n",
      "13         0.038884                0.031916                0.030858   \n",
      "14         0.101858                0.039493                0.030308   \n",
      "15         0.073507                0.035712                0.034184   \n",
      "16         0.063764                0.044679                0.037688   \n",
      "17         0.122147                0.040594                0.048531   \n",
      "\n",
      "    ViT-B-32;laion400m_e31  RN50;openai  RN50;yfcc15m  RN50;cc12m  \\\n",
      "0                 0.031858     0.076289      0.298224    0.243863   \n",
      "1                 0.034588     0.089701      0.177471    0.240306   \n",
      "2                 0.023541     0.029134      0.274205    0.251653   \n",
      "3                 0.034430     0.052215      0.182620    0.175592   \n",
      "4                 0.029081     0.041185      0.229319    0.139610   \n",
      "5                 0.029669     0.081426      0.196032    0.221879   \n",
      "6                 0.029563     0.048513      0.223634    0.227368   \n",
      "7                 0.035480     0.041658      0.246183    0.250358   \n",
      "8                 0.040406     0.097298      0.279534    0.301198   \n",
      "9                 0.034844     0.076154      0.338492    0.293334   \n",
      "10                0.033034     0.092313      0.199082    0.261134   \n",
      "11                0.027735     0.053063      0.266768    0.260330   \n",
      "12                0.038848     0.072184      0.307081    0.178683   \n",
      "13                0.037137     0.057845      0.298278    0.189444   \n",
      "14                0.032729     0.076811      0.266216    0.274836   \n",
      "15                0.031548     0.054111      0.312276    0.217911   \n",
      "16                0.033064     0.073716      0.239136    0.372883   \n",
      "17                0.028963     0.049731      0.321638    0.364339   \n",
      "\n",
      "    ViT-H-14;laion2b_s32b_b79k  \n",
      "0                     0.009523  \n",
      "1                     0.004875  \n",
      "2                     0.003986  \n",
      "3                     0.007756  \n",
      "4                     0.006740  \n",
      "5                     0.007089  \n",
      "6                     0.008725  \n",
      "7                     0.010667  \n",
      "8                     0.006436  \n",
      "9                     0.011080  \n",
      "10                    0.003662  \n",
      "11                    0.002707  \n",
      "12                    0.006242  \n",
      "13                    0.006712  \n",
      "14                    0.004902  \n",
      "15                    0.006032  \n",
      "16                    0.009753  \n",
      "17                    0.017397  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [14:27<00:00, 66.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ViT-B-16;laion2b_s34b_b88k  ViT-L-14;laion2b_s32b_b82k  \\\n",
      "0                    0.017865                    0.015185   \n",
      "\n",
      "   ViT-B-32;laion2b_s34b_b79k  ViT-B-16;openai  ViT-L-14;openai  \\\n",
      "0                    0.028567         0.029396         0.015401   \n",
      "\n",
      "   ViT-B-32;openai  ViT-B-16;laion400m_e31  ViT-L-14;laion400m_e31  \\\n",
      "0         0.029977                0.044579                0.033489   \n",
      "\n",
      "   ViT-B-32;laion400m_e31  RN50;openai  RN50;yfcc15m  RN50;cc12m  \\\n",
      "0                0.025616     0.047133      0.228004    0.268225   \n",
      "\n",
      "   ViT-H-14;laion2b_s32b_b79k  \n",
      "0                    0.015839  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/13 [01:59<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/ubuntu/code/clip_miscalibration/imagenet_tune.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbenp_8gpu/home/ubuntu/code/clip_miscalibration/imagenet_tune.ipynb#Y101sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m _ , templates \u001b[39m=\u001b[39m get_openai_prompts(dataset_name)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbenp_8gpu/home/ubuntu/code/clip_miscalibration/imagenet_tune.ipynb#Y101sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m template_eces \u001b[39m=\u001b[39m []\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bbenp_8gpu/home/ubuntu/code/clip_miscalibration/imagenet_tune.ipynb#Y101sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m image_features, actual \u001b[39m=\u001b[39m get_image_features(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbenp_8gpu/home/ubuntu/code/clip_miscalibration/imagenet_tune.ipynb#Y101sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m     model,  dset,  batch_size\u001b[39m=\u001b[39;49mbatch_size, device\u001b[39m=\u001b[39;49mdevice\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbenp_8gpu/home/ubuntu/code/clip_miscalibration/imagenet_tune.ipynb#Y101sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbenp_8gpu/home/ubuntu/code/clip_miscalibration/imagenet_tune.ipynb#Y101sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mfor\u001b[39;00m text_template \u001b[39min\u001b[39;00m templates:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbenp_8gpu/home/ubuntu/code/clip_miscalibration/imagenet_tune.ipynb#Y101sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m     \u001b[39m#predictions, actual, probs = get_preds(model, tokenizer, dset, \u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbenp_8gpu/home/ubuntu/code/clip_miscalibration/imagenet_tune.ipynb#Y101sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m     \u001b[39m#    text_template=text_template, temp_scaling=temp, device=device)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbenp_8gpu/home/ubuntu/code/clip_miscalibration/imagenet_tune.ipynb#Y101sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m     predictions, probs \u001b[39m=\u001b[39m get_preds_from_img_features(model, tokenizer, dset, image_features, text_template\u001b[39m=\u001b[39mtext_template, \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbenp_8gpu/home/ubuntu/code/clip_miscalibration/imagenet_tune.ipynb#Y101sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m         \u001b[39m#temp_scaling=temp,\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbenp_8gpu/home/ubuntu/code/clip_miscalibration/imagenet_tune.ipynb#Y101sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m         device \u001b[39m=\u001b[39m device)\n",
      "File \u001b[0;32m~/code/clip_miscalibration/util.py:18\u001b[0m, in \u001b[0;36mget_image_features\u001b[0;34m(model, dset, batch_size, device)\u001b[0m\n\u001b[1;32m     16\u001b[0m actual \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([])\n\u001b[1;32m     17\u001b[0m all_img_features \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[39mfor\u001b[39;00m i, (images, labels) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(dataloader, \u001b[39m0\u001b[39m):\n\u001b[1;32m     19\u001b[0m     images \u001b[39m=\u001b[39m images\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     20\u001b[0m     model\u001b[39m.\u001b[39meval()\n",
      "File \u001b[0;32m~/anaconda3/envs/content_understanding/lib/python3.8/site-packages/torch/utils/data/dataloader.py:652\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    650\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    651\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 652\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    653\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    654\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    655\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    656\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/content_understanding/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1330\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1327\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_data(data)\n\u001b[1;32m   1329\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m-> 1330\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data()\n\u001b[1;32m   1331\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1332\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable:\n\u001b[1;32m   1333\u001b[0m     \u001b[39m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/content_understanding/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1296\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1292\u001b[0m     \u001b[39m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1293\u001b[0m     \u001b[39m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1294\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1295\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m-> 1296\u001b[0m         success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_get_data()\n\u001b[1;32m   1297\u001b[0m         \u001b[39mif\u001b[39;00m success:\n\u001b[1;32m   1298\u001b[0m             \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/anaconda3/envs/content_understanding/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1134\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1121\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_get_data\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m_utils\u001b[39m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1122\u001b[0m     \u001b[39m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1123\u001b[0m     \u001b[39m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1131\u001b[0m     \u001b[39m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m     \u001b[39m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1134\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m   1135\u001b[0m         \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n\u001b[1;32m   1136\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1137\u001b[0m         \u001b[39m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m         \u001b[39m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1139\u001b[0m         \u001b[39m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/content_understanding/lib/python3.8/multiprocessing/queues.py:107\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[39mif\u001b[39;00m block:\n\u001b[1;32m    106\u001b[0m     timeout \u001b[39m=\u001b[39m deadline \u001b[39m-\u001b[39m time\u001b[39m.\u001b[39mmonotonic()\n\u001b[0;32m--> 107\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout):\n\u001b[1;32m    108\u001b[0m         \u001b[39mraise\u001b[39;00m Empty\n\u001b[1;32m    109\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_poll():\n",
      "File \u001b[0;32m~/anaconda3/envs/content_understanding/lib/python3.8/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_closed()\n\u001b[1;32m    256\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout)\n",
      "File \u001b[0;32m~/anaconda3/envs/content_understanding/lib/python3.8/multiprocessing/connection.py:424\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_poll\u001b[39m(\u001b[39mself\u001b[39m, timeout):\n\u001b[0;32m--> 424\u001b[0m     r \u001b[39m=\u001b[39m wait([\u001b[39mself\u001b[39;49m], timeout)\n\u001b[1;32m    425\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mbool\u001b[39m(r)\n",
      "File \u001b[0;32m~/anaconda3/envs/content_understanding/lib/python3.8/multiprocessing/connection.py:931\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    928\u001b[0m     deadline \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mmonotonic() \u001b[39m+\u001b[39m timeout\n\u001b[1;32m    930\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     ready \u001b[39m=\u001b[39m selector\u001b[39m.\u001b[39;49mselect(timeout)\n\u001b[1;32m    932\u001b[0m     \u001b[39mif\u001b[39;00m ready:\n\u001b[1;32m    933\u001b[0m         \u001b[39mreturn\u001b[39;00m [key\u001b[39m.\u001b[39mfileobj \u001b[39mfor\u001b[39;00m (key, events) \u001b[39min\u001b[39;00m ready]\n",
      "File \u001b[0;32m~/anaconda3/envs/content_understanding/lib/python3.8/selectors.py:415\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m ready \u001b[39m=\u001b[39m []\n\u001b[1;32m    414\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 415\u001b[0m     fd_event_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_selector\u001b[39m.\u001b[39;49mpoll(timeout)\n\u001b[1;32m    416\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mInterruptedError\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     \u001b[39mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#dataset_eces_uncalib = {}\n",
    "for dataset_name in ['CIFAR100', 'CIFAR10', 'Food101', 'SUN397']:\n",
    "    dset,_ = get_test_set(dataset_name, None)\n",
    "    model_eces = {}\n",
    "    for model_legend, _ in tqdm(all_temps.items()):\n",
    "        model_name, pretrained_dset = model_legend.split(';')\n",
    "        model, _, preprocess = open_clip.create_model_and_transforms(model_name,\n",
    "            pretrained=pretrained_dset,\n",
    "            device=device)\n",
    "        tokenizer = open_clip.get_tokenizer(model_name)\n",
    "        if isinstance(dset, torch.utils.data.dataset.Subset):\n",
    "            dset.dataset.transform = preprocess\n",
    "        else:\n",
    "            dset.transform = preprocess\n",
    "        _ , templates = get_openai_prompts(dataset_name)\n",
    "\n",
    "        template_eces = []\n",
    "        image_features, actual = get_image_features(\n",
    "            model,  dset,  batch_size=batch_size, device=device\n",
    "        )\n",
    "        for text_template in templates:\n",
    "            #predictions, actual, probs = get_preds(model, tokenizer, dset, \n",
    "            #    text_template=text_template, temp_scaling=temp, device=device)\n",
    "\n",
    "            predictions, probs = get_preds_from_img_features(model, tokenizer, dset, image_features, text_template=text_template, \n",
    "                #temp_scaling=temp,\n",
    "                device = device)\n",
    "\n",
    "            ECE, _, acc = get_metrics(predictions, actual, probs)\n",
    "            template_eces.append(ECE)\n",
    "        \n",
    "        model_eces[model_legend] = template_eces\n",
    "    dataset_eces_uncalib[dataset_name] = model_eces\n",
    "    print(pd.DataFrame(model_eces))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ViT-B-16;laion2b_s34b_b88k</th>\n",
       "      <th>ViT-L-14;laion2b_s32b_b82k</th>\n",
       "      <th>ViT-B-32;laion2b_s34b_b79k</th>\n",
       "      <th>ViT-B-16;openai</th>\n",
       "      <th>ViT-L-14;openai</th>\n",
       "      <th>ViT-B-32;openai</th>\n",
       "      <th>ViT-B-16;laion400m_e31</th>\n",
       "      <th>ViT-L-14;laion400m_e31</th>\n",
       "      <th>ViT-B-32;laion400m_e31</th>\n",
       "      <th>RN50;openai</th>\n",
       "      <th>RN50;yfcc15m</th>\n",
       "      <th>RN50;cc12m</th>\n",
       "      <th>ViT-H-14;laion2b_s32b_b79k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.017865</td>\n",
       "      <td>0.015185</td>\n",
       "      <td>0.028567</td>\n",
       "      <td>0.029396</td>\n",
       "      <td>0.015401</td>\n",
       "      <td>0.029977</td>\n",
       "      <td>0.044579</td>\n",
       "      <td>0.033489</td>\n",
       "      <td>0.025616</td>\n",
       "      <td>0.047133</td>\n",
       "      <td>0.228004</td>\n",
       "      <td>0.268225</td>\n",
       "      <td>0.015839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ViT-B-16;laion2b_s34b_b88k  ViT-L-14;laion2b_s32b_b82k  \\\n",
       "0                    0.017865                    0.015185   \n",
       "\n",
       "   ViT-B-32;laion2b_s34b_b79k  ViT-B-16;openai  ViT-L-14;openai  \\\n",
       "0                    0.028567         0.029396         0.015401   \n",
       "\n",
       "   ViT-B-32;openai  ViT-B-16;laion400m_e31  ViT-L-14;laion400m_e31  \\\n",
       "0         0.029977                0.044579                0.033489   \n",
       "\n",
       "   ViT-B-32;laion400m_e31  RN50;openai  RN50;yfcc15m  RN50;cc12m  \\\n",
       "0                0.025616     0.047133      0.228004    0.268225   \n",
       "\n",
       "   ViT-H-14;laion2b_s32b_b79k  \n",
       "0                    0.015839  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(dataset_eces_uncalib['Food101'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 6/13 [28:28<32:35, 279.33s/it]  "
     ]
    }
   ],
   "source": [
    "for dataset_name in ['SUN397']:\n",
    "    dset,_ = get_test_set(dataset_name, None)\n",
    "    model_eces = {}\n",
    "    for model_legend, temp in tqdm(all_temps.items()):\n",
    "        model_name, pretrained_dset = model_legend.split(';')\n",
    "        model, _, preprocess = open_clip.create_model_and_transforms(model_name,\n",
    "            pretrained=pretrained_dset,\n",
    "            device=device)\n",
    "        tokenizer = open_clip.get_tokenizer(model_name)\n",
    "        if isinstance(dset, torch.utils.data.dataset.Subset):\n",
    "            dset.dataset.transform = preprocess\n",
    "        else:\n",
    "            dset.transform = preprocess\n",
    "        _ , templates = get_openai_prompts(dataset_name)\n",
    "\n",
    "        template_eces = []\n",
    "        image_features, actual = get_image_features(\n",
    "            model,  dset,  batch_size=batch_size, device=device\n",
    "        )\n",
    "        for text_template in templates:\n",
    "            #predictions, actual, probs = get_preds(model, tokenizer, dset, \n",
    "            #    text_template=text_template, temp_scaling=temp, device=device)\n",
    "\n",
    "            predictions, probs = get_preds_from_img_features(model, tokenizer, dset, image_features, text_template=text_template, \n",
    "                #temp_scaling=temp,\n",
    "                device = device)\n",
    "\n",
    "            ECE, _, acc = get_metrics(predictions, actual, probs)\n",
    "            template_eces.append(ECE)\n",
    "        \n",
    "        model_eces[model_legend] = template_eces\n",
    "    dataset_eces_uncalib[dataset_name] = model_eces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ViT-B-16;laion2b_s34b_b88k</th>\n",
       "      <th>ViT-L-14;laion2b_s32b_b82k</th>\n",
       "      <th>ViT-B-32;laion2b_s34b_b79k</th>\n",
       "      <th>ViT-B-16;openai</th>\n",
       "      <th>ViT-L-14;openai</th>\n",
       "      <th>ViT-B-32;openai</th>\n",
       "      <th>ViT-B-16;laion400m_e31</th>\n",
       "      <th>ViT-L-14;laion400m_e31</th>\n",
       "      <th>ViT-B-32;laion400m_e31</th>\n",
       "      <th>RN50;openai</th>\n",
       "      <th>RN50;yfcc15m</th>\n",
       "      <th>RN50;cc12m</th>\n",
       "      <th>ViT-H-14;laion2b_s32b_b79k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.016477</td>\n",
       "      <td>0.015790</td>\n",
       "      <td>0.023797</td>\n",
       "      <td>0.052869</td>\n",
       "      <td>0.048692</td>\n",
       "      <td>0.049168</td>\n",
       "      <td>0.060085</td>\n",
       "      <td>0.074716</td>\n",
       "      <td>0.041315</td>\n",
       "      <td>0.076222</td>\n",
       "      <td>0.301586</td>\n",
       "      <td>0.244496</td>\n",
       "      <td>0.022556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.005005</td>\n",
       "      <td>0.006279</td>\n",
       "      <td>0.014653</td>\n",
       "      <td>0.053697</td>\n",
       "      <td>0.053440</td>\n",
       "      <td>0.040927</td>\n",
       "      <td>0.052569</td>\n",
       "      <td>0.046396</td>\n",
       "      <td>0.041712</td>\n",
       "      <td>0.089666</td>\n",
       "      <td>0.180283</td>\n",
       "      <td>0.243485</td>\n",
       "      <td>0.008576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.009754</td>\n",
       "      <td>0.005568</td>\n",
       "      <td>0.019888</td>\n",
       "      <td>0.029596</td>\n",
       "      <td>0.039544</td>\n",
       "      <td>0.021597</td>\n",
       "      <td>0.045846</td>\n",
       "      <td>0.047120</td>\n",
       "      <td>0.028131</td>\n",
       "      <td>0.029100</td>\n",
       "      <td>0.280472</td>\n",
       "      <td>0.252140</td>\n",
       "      <td>0.007252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.017640</td>\n",
       "      <td>0.013397</td>\n",
       "      <td>0.017957</td>\n",
       "      <td>0.049189</td>\n",
       "      <td>0.037274</td>\n",
       "      <td>0.041498</td>\n",
       "      <td>0.059882</td>\n",
       "      <td>0.057221</td>\n",
       "      <td>0.045282</td>\n",
       "      <td>0.052157</td>\n",
       "      <td>0.183357</td>\n",
       "      <td>0.176376</td>\n",
       "      <td>0.017618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.013293</td>\n",
       "      <td>0.011741</td>\n",
       "      <td>0.019585</td>\n",
       "      <td>0.040568</td>\n",
       "      <td>0.034073</td>\n",
       "      <td>0.012950</td>\n",
       "      <td>0.048032</td>\n",
       "      <td>0.062678</td>\n",
       "      <td>0.035936</td>\n",
       "      <td>0.041095</td>\n",
       "      <td>0.230471</td>\n",
       "      <td>0.139998</td>\n",
       "      <td>0.014786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.020227</td>\n",
       "      <td>0.011280</td>\n",
       "      <td>0.022900</td>\n",
       "      <td>0.058637</td>\n",
       "      <td>0.055680</td>\n",
       "      <td>0.071162</td>\n",
       "      <td>0.067231</td>\n",
       "      <td>0.066970</td>\n",
       "      <td>0.036518</td>\n",
       "      <td>0.081492</td>\n",
       "      <td>0.196379</td>\n",
       "      <td>0.222628</td>\n",
       "      <td>0.014313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.014800</td>\n",
       "      <td>0.012401</td>\n",
       "      <td>0.023917</td>\n",
       "      <td>0.069136</td>\n",
       "      <td>0.052788</td>\n",
       "      <td>0.057587</td>\n",
       "      <td>0.064864</td>\n",
       "      <td>0.083470</td>\n",
       "      <td>0.037807</td>\n",
       "      <td>0.048480</td>\n",
       "      <td>0.224352</td>\n",
       "      <td>0.227845</td>\n",
       "      <td>0.020242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.023362</td>\n",
       "      <td>0.015036</td>\n",
       "      <td>0.035868</td>\n",
       "      <td>0.045805</td>\n",
       "      <td>0.058565</td>\n",
       "      <td>0.044232</td>\n",
       "      <td>0.072784</td>\n",
       "      <td>0.081710</td>\n",
       "      <td>0.044215</td>\n",
       "      <td>0.041976</td>\n",
       "      <td>0.249727</td>\n",
       "      <td>0.250848</td>\n",
       "      <td>0.022378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.016674</td>\n",
       "      <td>0.043433</td>\n",
       "      <td>0.035388</td>\n",
       "      <td>0.087863</td>\n",
       "      <td>0.101702</td>\n",
       "      <td>0.088415</td>\n",
       "      <td>0.052829</td>\n",
       "      <td>0.066712</td>\n",
       "      <td>0.047753</td>\n",
       "      <td>0.097319</td>\n",
       "      <td>0.280751</td>\n",
       "      <td>0.302008</td>\n",
       "      <td>0.010700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.010787</td>\n",
       "      <td>0.011210</td>\n",
       "      <td>0.021534</td>\n",
       "      <td>0.063763</td>\n",
       "      <td>0.076167</td>\n",
       "      <td>0.078766</td>\n",
       "      <td>0.054817</td>\n",
       "      <td>0.088222</td>\n",
       "      <td>0.042147</td>\n",
       "      <td>0.076091</td>\n",
       "      <td>0.341650</td>\n",
       "      <td>0.294014</td>\n",
       "      <td>0.016334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.003063</td>\n",
       "      <td>0.006424</td>\n",
       "      <td>0.008294</td>\n",
       "      <td>0.064887</td>\n",
       "      <td>0.058174</td>\n",
       "      <td>0.078614</td>\n",
       "      <td>0.048406</td>\n",
       "      <td>0.043564</td>\n",
       "      <td>0.036524</td>\n",
       "      <td>0.092260</td>\n",
       "      <td>0.202347</td>\n",
       "      <td>0.265096</td>\n",
       "      <td>0.005872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.008545</td>\n",
       "      <td>0.007672</td>\n",
       "      <td>0.016065</td>\n",
       "      <td>0.049290</td>\n",
       "      <td>0.065306</td>\n",
       "      <td>0.050601</td>\n",
       "      <td>0.052027</td>\n",
       "      <td>0.050925</td>\n",
       "      <td>0.031987</td>\n",
       "      <td>0.053015</td>\n",
       "      <td>0.272674</td>\n",
       "      <td>0.260600</td>\n",
       "      <td>0.004124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.017199</td>\n",
       "      <td>0.006691</td>\n",
       "      <td>0.016462</td>\n",
       "      <td>0.068417</td>\n",
       "      <td>0.059426</td>\n",
       "      <td>0.065311</td>\n",
       "      <td>0.050424</td>\n",
       "      <td>0.061078</td>\n",
       "      <td>0.047319</td>\n",
       "      <td>0.072249</td>\n",
       "      <td>0.310234</td>\n",
       "      <td>0.179152</td>\n",
       "      <td>0.012035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.011864</td>\n",
       "      <td>0.007555</td>\n",
       "      <td>0.018464</td>\n",
       "      <td>0.060724</td>\n",
       "      <td>0.053996</td>\n",
       "      <td>0.038831</td>\n",
       "      <td>0.046725</td>\n",
       "      <td>0.066419</td>\n",
       "      <td>0.044364</td>\n",
       "      <td>0.057885</td>\n",
       "      <td>0.301014</td>\n",
       "      <td>0.190199</td>\n",
       "      <td>0.012156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.014044</td>\n",
       "      <td>0.009676</td>\n",
       "      <td>0.014784</td>\n",
       "      <td>0.058658</td>\n",
       "      <td>0.078307</td>\n",
       "      <td>0.101810</td>\n",
       "      <td>0.059527</td>\n",
       "      <td>0.068691</td>\n",
       "      <td>0.037683</td>\n",
       "      <td>0.076870</td>\n",
       "      <td>0.266490</td>\n",
       "      <td>0.275966</td>\n",
       "      <td>0.007743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.010872</td>\n",
       "      <td>0.010197</td>\n",
       "      <td>0.016865</td>\n",
       "      <td>0.075760</td>\n",
       "      <td>0.075855</td>\n",
       "      <td>0.073610</td>\n",
       "      <td>0.054202</td>\n",
       "      <td>0.088785</td>\n",
       "      <td>0.037479</td>\n",
       "      <td>0.054227</td>\n",
       "      <td>0.313674</td>\n",
       "      <td>0.218144</td>\n",
       "      <td>0.009634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.020421</td>\n",
       "      <td>0.011982</td>\n",
       "      <td>0.031515</td>\n",
       "      <td>0.064146</td>\n",
       "      <td>0.079657</td>\n",
       "      <td>0.063778</td>\n",
       "      <td>0.067266</td>\n",
       "      <td>0.084981</td>\n",
       "      <td>0.039217</td>\n",
       "      <td>0.073711</td>\n",
       "      <td>0.241712</td>\n",
       "      <td>0.373707</td>\n",
       "      <td>0.016731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.030810</td>\n",
       "      <td>0.010522</td>\n",
       "      <td>0.022911</td>\n",
       "      <td>0.126214</td>\n",
       "      <td>0.120393</td>\n",
       "      <td>0.122139</td>\n",
       "      <td>0.049262</td>\n",
       "      <td>0.087348</td>\n",
       "      <td>0.030665</td>\n",
       "      <td>0.049792</td>\n",
       "      <td>0.322592</td>\n",
       "      <td>0.365860</td>\n",
       "      <td>0.021597</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ViT-B-16;laion2b_s34b_b88k  ViT-L-14;laion2b_s32b_b82k  \\\n",
       "0                     0.016477                    0.015790   \n",
       "1                     0.005005                    0.006279   \n",
       "2                     0.009754                    0.005568   \n",
       "3                     0.017640                    0.013397   \n",
       "4                     0.013293                    0.011741   \n",
       "5                     0.020227                    0.011280   \n",
       "6                     0.014800                    0.012401   \n",
       "7                     0.023362                    0.015036   \n",
       "8                     0.016674                    0.043433   \n",
       "9                     0.010787                    0.011210   \n",
       "10                    0.003063                    0.006424   \n",
       "11                    0.008545                    0.007672   \n",
       "12                    0.017199                    0.006691   \n",
       "13                    0.011864                    0.007555   \n",
       "14                    0.014044                    0.009676   \n",
       "15                    0.010872                    0.010197   \n",
       "16                    0.020421                    0.011982   \n",
       "17                    0.030810                    0.010522   \n",
       "\n",
       "    ViT-B-32;laion2b_s34b_b79k  ViT-B-16;openai  ViT-L-14;openai  \\\n",
       "0                     0.023797         0.052869         0.048692   \n",
       "1                     0.014653         0.053697         0.053440   \n",
       "2                     0.019888         0.029596         0.039544   \n",
       "3                     0.017957         0.049189         0.037274   \n",
       "4                     0.019585         0.040568         0.034073   \n",
       "5                     0.022900         0.058637         0.055680   \n",
       "6                     0.023917         0.069136         0.052788   \n",
       "7                     0.035868         0.045805         0.058565   \n",
       "8                     0.035388         0.087863         0.101702   \n",
       "9                     0.021534         0.063763         0.076167   \n",
       "10                    0.008294         0.064887         0.058174   \n",
       "11                    0.016065         0.049290         0.065306   \n",
       "12                    0.016462         0.068417         0.059426   \n",
       "13                    0.018464         0.060724         0.053996   \n",
       "14                    0.014784         0.058658         0.078307   \n",
       "15                    0.016865         0.075760         0.075855   \n",
       "16                    0.031515         0.064146         0.079657   \n",
       "17                    0.022911         0.126214         0.120393   \n",
       "\n",
       "    ViT-B-32;openai  ViT-B-16;laion400m_e31  ViT-L-14;laion400m_e31  \\\n",
       "0          0.049168                0.060085                0.074716   \n",
       "1          0.040927                0.052569                0.046396   \n",
       "2          0.021597                0.045846                0.047120   \n",
       "3          0.041498                0.059882                0.057221   \n",
       "4          0.012950                0.048032                0.062678   \n",
       "5          0.071162                0.067231                0.066970   \n",
       "6          0.057587                0.064864                0.083470   \n",
       "7          0.044232                0.072784                0.081710   \n",
       "8          0.088415                0.052829                0.066712   \n",
       "9          0.078766                0.054817                0.088222   \n",
       "10         0.078614                0.048406                0.043564   \n",
       "11         0.050601                0.052027                0.050925   \n",
       "12         0.065311                0.050424                0.061078   \n",
       "13         0.038831                0.046725                0.066419   \n",
       "14         0.101810                0.059527                0.068691   \n",
       "15         0.073610                0.054202                0.088785   \n",
       "16         0.063778                0.067266                0.084981   \n",
       "17         0.122139                0.049262                0.087348   \n",
       "\n",
       "    ViT-B-32;laion400m_e31  RN50;openai  RN50;yfcc15m  RN50;cc12m  \\\n",
       "0                 0.041315     0.076222      0.301586    0.244496   \n",
       "1                 0.041712     0.089666      0.180283    0.243485   \n",
       "2                 0.028131     0.029100      0.280472    0.252140   \n",
       "3                 0.045282     0.052157      0.183357    0.176376   \n",
       "4                 0.035936     0.041095      0.230471    0.139998   \n",
       "5                 0.036518     0.081492      0.196379    0.222628   \n",
       "6                 0.037807     0.048480      0.224352    0.227845   \n",
       "7                 0.044215     0.041976      0.249727    0.250848   \n",
       "8                 0.047753     0.097319      0.280751    0.302008   \n",
       "9                 0.042147     0.076091      0.341650    0.294014   \n",
       "10                0.036524     0.092260      0.202347    0.265096   \n",
       "11                0.031987     0.053015      0.272674    0.260600   \n",
       "12                0.047319     0.072249      0.310234    0.179152   \n",
       "13                0.044364     0.057885      0.301014    0.190199   \n",
       "14                0.037683     0.076870      0.266490    0.275966   \n",
       "15                0.037479     0.054227      0.313674    0.218144   \n",
       "16                0.039217     0.073711      0.241712    0.373707   \n",
       "17                0.030665     0.049792      0.322592    0.365860   \n",
       "\n",
       "    ViT-H-14;laion2b_s32b_b79k  \n",
       "0                     0.022556  \n",
       "1                     0.008576  \n",
       "2                     0.007252  \n",
       "3                     0.017618  \n",
       "4                     0.014786  \n",
       "5                     0.014313  \n",
       "6                     0.020242  \n",
       "7                     0.022378  \n",
       "8                     0.010700  \n",
       "9                     0.016334  \n",
       "10                    0.005872  \n",
       "11                    0.004124  \n",
       "12                    0.012035  \n",
       "13                    0.012156  \n",
       "14                    0.007743  \n",
       "15                    0.009634  \n",
       "16                    0.016731  \n",
       "17                    0.021597  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(dataset_eces_uncalib['CIFAR10'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_features, actual = get_image_features(model, imagenet_test, batch_size=128,\n",
    "        device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual = torch.IntTensor(actual).to(device).long()\n",
    "actual.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_mapping = map_imagenet_to_readable_label()\n",
    "imagenet_test.classes = [imagenet_mapping[x] for x in imagenet_test.classes ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = tokenizer([text_template.replace('{}',x) for x in imagenet_test.classes])\n",
    "with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "    text_features = model.encode_text(text.to(device))\n",
    "    text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "    \n",
    "text_probs = (100.0 * image_features @ text_features.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6131701469421387"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Setup LBGFS\n",
    "temperature = nn.Parameter((torch.ones(1)).to(device))\n",
    "args = {'temperature': temperature}\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Removing strong_wolfe line search results in jump after 50 epochs\n",
    "optimizer = optim.LBFGS([temperature], lr=0.001, max_iter=1000, line_search_fn='strong_wolfe')\n",
    "\n",
    "temps = []\n",
    "losses = []\n",
    "def _eval():\n",
    "    loss = criterion(T_scaling(text_probs, args), actual)\n",
    "    loss.backward()\n",
    "    temps.append(temperature.item())\n",
    "    losses.append(loss)\n",
    "    return loss\n",
    "optimizer.step(_eval)\n",
    "temperature.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.620787089606212, 0.958984375, 0.0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions, probs = get_preds_from_img_features(\n",
    "    model, tokenizer, imagenet_test, image_features, text_template=text_template, temp_scaling=temperature.item(), device = device\n",
    ")\n",
    "get_metrics(predictions, actual, probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.025181555526703616, 0.057354552355015076, 0.7139)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cifar_test, num_classes = get_test_set('CIFAR100', preprocess)\n",
    "predictions, actual, probs = get_preds(model, tokenizer, cifar_test, \n",
    "    text_template=text_template, temp_scaling=temperature.item(), device=device)\n",
    "get_metrics(predictions, actual, probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.007352347984910052, 0.18847142159938812, 0.9174)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cifar_test, num_classes = get_test_set('CIFAR10', preprocess)\n",
    "predictions, actual, probs = get_preds(model, tokenizer, cifar_test, \n",
    "    text_template=text_template, temp_scaling=temperature.item(), device=device)\n",
    "get_metrics(predictions, actual, probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "content_understanding",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6d36b139402f0f8909133622e5e80cdd43397350f551386f6df555aa508ab69d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
