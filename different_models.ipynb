{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/content_understanding/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import open_clip\n",
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "from PIL import Image\n",
    "import open_clip\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from sklearn import calibration\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.tree import DecisionTreeRegressor as DT\n",
    "from sklearn.isotonic import IsotonicRegression as IR\n",
    "from scipy.stats import norm\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import get_preds, calc_bins, get_metrics, T_scaling, find_temp_scale, get_openai_prompts, get_val_set, find_temp_scale_with_q, get_text_probs, sample_quantile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_to_consider = [\n",
    "    #('ViT-B-32' , 'laion2b_s34b_b79k'),\n",
    "    ('ViT-L-14' , 'laion2b_s32b_b82k'),\n",
    "    ('ViT-H-14' , 'laion2b_s32b_b79k'),\n",
    "    #('ViT-bigG-14' , 'laion2b_s39b_b160k'),\n",
    "    #('ViT-B-32', 'openai')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_full_run():\n",
    "    dataset_name = 'CIFAR100'\n",
    "    num_classes = 100\n",
    "    cifar_test = datasets.CIFAR100('/home/ubuntu/data/', train = False, transform = preprocess, download=True)\n",
    "    classes, templates = get_openai_prompts(dataset_name)\n",
    "    cifar_test.classes = classes\n",
    "    val_dset = get_val_set(dataset_name, classes, preprocess)\n",
    "    # No scaling\n",
    "    eces = []\n",
    "    mces = []\n",
    "    accs = []\n",
    "    for t in tqdm(templates):\n",
    "        predictions, actual, probs = get_preds(model, tokenizer, cifar_test, text_template=t, device=device)\n",
    "        ece, mce, acc = get_metrics(predictions, actual, probs)\n",
    "        eces.append(ece)\n",
    "        accs.append(acc)\n",
    "        mces.append(mce)\n",
    "\n",
    "    # With scaling\n",
    "    eces_scaled = []\n",
    "    mces_scaled = []\n",
    "    accs_scaled = []\n",
    "    temps = []\n",
    "    for t in tqdm(templates):\n",
    "        scaled_temp = find_temp_scale(model, tokenizer, val_dset, num_classes=num_classes, text_template=t, device=device)\n",
    "        predictions, actual, probs = get_preds(model, tokenizer, cifar_test, text_template=t, temp_scaling=scaled_temp, device=device)\n",
    "        ece, mce, acc = get_metrics(predictions, actual, probs)\n",
    "        eces_scaled.append(ece)\n",
    "        accs_scaled.append(acc)\n",
    "        mces_scaled.append(mce)\n",
    "        temps.append(scaled_temp)\n",
    "\n",
    "    with open(f'numbers/q1.0/{dataset_name}_{model_name}_{pretrained_dset}_acrossprompt.json', 'w') as f:\n",
    "        json.dump({\n",
    "            'eces_scaled' : eces_scaled,\n",
    "            'mces_scaled' : mces_scaled,\n",
    "            'accs_scaled' : accs_scaled,\n",
    "            'eces' : eces,\n",
    "            'mces' : mces,\n",
    "            'accs' : accs,\n",
    "            'temps' : temps\n",
    "        },f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [17:07<00:00, 54.06s/it]\n",
      "100%|██████████| 19/19 [33:43<00:00, 106.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [29:35<00:00, 93.43s/it]\n",
      "100%|██████████| 19/19 [58:17<00:00, 184.08s/it]\n"
     ]
    }
   ],
   "source": [
    "for model_name, pretrained_dset in models_to_consider:\n",
    "    model, _, preprocess = open_clip.create_model_and_transforms(model_name, pretrained=pretrained_dset, device=device)\n",
    "    tokenizer = open_clip.get_tokenizer(model_name)\n",
    "    do_full_run()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "content_understanding",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6d36b139402f0f8909133622e5e80cdd43397350f551386f6df555aa508ab69d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
